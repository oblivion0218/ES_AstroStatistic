{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d8cb22c",
   "metadata": {},
   "source": [
    "# Time to get your hands dirty. Your first neural network; pick your favourite.\n",
    "For the last coding assignment, you'll need to implement a neural network. We'll look at a relatively simple binary classification problem. Here below are three options; completing one of them for the exam is enough\n",
    "## Tasks:\n",
    "- Remember: scale your data appropriately\n",
    "\n",
    "- Decide on a testing strategy (a simple test/train split? a CV strategy? set a test set aside to be looked at at the very end?)\n",
    "\n",
    "- Decide your optimization metric.\n",
    "\n",
    "- Write down your network architecture. You can start from a fully connected, multi-layer perceptron (and then explore)\n",
    "\n",
    "- Use one the package among those we've seen. These include Tensorflow via keras, pytorch, and the MPL classifier implemented in scikit-learn. This is an opportunity to pick the one you're most interested in learning.\n",
    "\n",
    "- Optimize the hyperparameters of your network. Explore different hyperparameters and see what fits the data best. Do your best now to optimize the network architecture. Be creative!\n",
    "\n",
    "- Report on the perfomance of the network on the test set; report other metrics that have not been optimized.\n",
    "\n",
    "## A few tips:\n",
    "- In scikit-learn, remember that you can utilize all availables cores on your machine with n_jobs=-1.\n",
    "Print out the classification score for the training data, and the best parameters obtained by the cross validation.\n",
    "- If it takes too long, run the hyperparameter optimization on a subset of the training set. Then retrain the full network using the best hyperparameters only.\n",
    "- On cross validation, for scikit learn we've seen how to use GridSearchCV already. For Tensorflow, there's a really cool tool called Tensorboard\n",
    "\n",
    "## Datasets:\n",
    "You can choose one of these three problems:\n",
    "\n",
    "1. Galaxies vs quasars (but with neural networks) Go back to our SDSS data we've used in Lecture 19. We had color differences, and the task was to classifty quasars vs galaxies. Repeat that task with a neural network.\n",
    "\n",
    "2. Can a computer learn if we're going to detect gravitational waves? (but with neural networks) Go back to the SNR classifier for gravitational wave events, same data we've used in Lecture. We had properties of black hole binaries, and the task was to classify. Repeat that task with a neural network.\n",
    "\n",
    "3. The HiggsML challenge Branching out of astrophysics, let's mess around with a dataset of simulated but realistic events from the ATLAS particle detector at CERN.\n",
    "\n",
    "- Data are at solutions/higgs.tar.gz (you need to uncompress with tar -czvf)\n",
    "- There are $N_{samples}=2.5x10^5$ entries with $N_{features}=30$ features each.\n",
    "- The taks is that of classifying these features against a set of labels, which are either s (source) or b (background).\n",
    "- For some info on both the physics and the dataset see this document; includes a description of the features and how data have been padded (-999) for missing values.\n",
    "- This dataset was part of a challenge that run on Kaggle in 2014: https://higgsml.ijclab.in2p3.fr/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ecaaa19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 15:13:02.968903: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751029983.194346    1429 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751029983.452433    1429 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-27 15:13:04.584836: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc718402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.91</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>41.928</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>67.435</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.473</td>\n",
       "      <td>2.078</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>46.226</td>\n",
       "      <td>2.233584</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.148</td>\n",
       "      <td>9.336</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>44.251</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>44.251</td>\n",
       "      <td>2.347389</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.310</td>\n",
       "      <td>0.414</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>5.446378</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.891</td>\n",
       "      <td>16.405</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.245333</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>349995</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>71.989</td>\n",
       "      <td>36.548</td>\n",
       "      <td>5.042</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>1.392</td>\n",
       "      <td>5.042</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.505083</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>349996</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>58.179</td>\n",
       "      <td>68.083</td>\n",
       "      <td>22.439</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.585</td>\n",
       "      <td>22.439</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>2.497259</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>349997</td>\n",
       "      <td>105.457</td>\n",
       "      <td>60.526</td>\n",
       "      <td>75.839</td>\n",
       "      <td>39.757</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.390</td>\n",
       "      <td>22.183</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>41.992</td>\n",
       "      <td>1.800</td>\n",
       "      <td>-0.166</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>41.992</td>\n",
       "      <td>0.018636</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>349998</td>\n",
       "      <td>94.951</td>\n",
       "      <td>19.362</td>\n",
       "      <td>68.812</td>\n",
       "      <td>13.504</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.365</td>\n",
       "      <td>13.504</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.681611</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>349999</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>72.756</td>\n",
       "      <td>70.831</td>\n",
       "      <td>7.479</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.025</td>\n",
       "      <td>7.479</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.877474</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        EventId  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  \\\n",
       "0        100000       138.470                       51.655        97.827   \n",
       "1        100001       160.937                       68.768       103.235   \n",
       "2        100002      -999.000                      162.172       125.953   \n",
       "3        100003       143.905                       81.417        80.943   \n",
       "4        100004       175.864                       16.915       134.805   \n",
       "...         ...           ...                          ...           ...   \n",
       "249995   349995      -999.000                       71.989        36.548   \n",
       "249996   349996      -999.000                       58.179        68.083   \n",
       "249997   349997       105.457                       60.526        75.839   \n",
       "249998   349998        94.951                       19.362        68.812   \n",
       "249999   349999      -999.000                       72.756        70.831   \n",
       "\n",
       "        DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0         27.980                  0.91           124.711                2.666   \n",
       "1         48.146               -999.00          -999.000             -999.000   \n",
       "2         35.635               -999.00          -999.000             -999.000   \n",
       "3          0.414               -999.00          -999.000             -999.000   \n",
       "4         16.405               -999.00          -999.000             -999.000   \n",
       "...          ...                   ...               ...                  ...   \n",
       "249995     5.042               -999.00          -999.000             -999.000   \n",
       "249996    22.439               -999.00          -999.000             -999.000   \n",
       "249997    39.757               -999.00          -999.000             -999.000   \n",
       "249998    13.504               -999.00          -999.000             -999.000   \n",
       "249999     7.479               -999.00          -999.000             -999.000   \n",
       "\n",
       "        DER_deltar_tau_lep  DER_pt_tot  ...  PRI_jet_num  PRI_jet_leading_pt  \\\n",
       "0                    3.064      41.928  ...            2              67.435   \n",
       "1                    3.473       2.078  ...            1              46.226   \n",
       "2                    3.148       9.336  ...            1              44.251   \n",
       "3                    3.310       0.414  ...            0            -999.000   \n",
       "4                    3.891      16.405  ...            0            -999.000   \n",
       "...                    ...         ...  ...          ...                 ...   \n",
       "249995               1.392       5.042  ...            0            -999.000   \n",
       "249996               2.585      22.439  ...            0            -999.000   \n",
       "249997               2.390      22.183  ...            1              41.992   \n",
       "249998               3.365      13.504  ...            0            -999.000   \n",
       "249999               2.025       7.479  ...            0            -999.000   \n",
       "\n",
       "        PRI_jet_leading_eta  PRI_jet_leading_phi  PRI_jet_subleading_pt  \\\n",
       "0                     2.150                0.444                 46.062   \n",
       "1                     0.725                1.158               -999.000   \n",
       "2                     2.053               -2.028               -999.000   \n",
       "3                  -999.000             -999.000               -999.000   \n",
       "4                  -999.000             -999.000               -999.000   \n",
       "...                     ...                  ...                    ...   \n",
       "249995             -999.000             -999.000               -999.000   \n",
       "249996             -999.000             -999.000               -999.000   \n",
       "249997                1.800               -0.166               -999.000   \n",
       "249998             -999.000             -999.000               -999.000   \n",
       "249999             -999.000             -999.000               -999.000   \n",
       "\n",
       "        PRI_jet_subleading_eta  PRI_jet_subleading_phi  PRI_jet_all_pt  \\\n",
       "0                         1.24                  -2.475         113.497   \n",
       "1                      -999.00                -999.000          46.226   \n",
       "2                      -999.00                -999.000          44.251   \n",
       "3                      -999.00                -999.000          -0.000   \n",
       "4                      -999.00                -999.000           0.000   \n",
       "...                        ...                     ...             ...   \n",
       "249995                 -999.00                -999.000           0.000   \n",
       "249996                 -999.00                -999.000          -0.000   \n",
       "249997                 -999.00                -999.000          41.992   \n",
       "249998                 -999.00                -999.000           0.000   \n",
       "249999                 -999.00                -999.000           0.000   \n",
       "\n",
       "          Weight  Label  \n",
       "0       0.002653      s  \n",
       "1       2.233584      b  \n",
       "2       2.347389      b  \n",
       "3       5.446378      b  \n",
       "4       6.245333      b  \n",
       "...          ...    ...  \n",
       "249995  4.505083      b  \n",
       "249996  2.497259      b  \n",
       "249997  0.018636      s  \n",
       "249998  1.681611      b  \n",
       "249999  1.877474      b  \n",
       "\n",
       "[250000 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/sara/higgs.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba801e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1429/3467513320.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['Label'] = data['Label'].replace({'s': 1, 'b': 0})\n"
     ]
    }
   ],
   "source": [
    "# Drop the ID column (not useful for training)\n",
    "data = df.drop(columns=['EventId'])\n",
    "# Replace labels: 's' -> 1, 'b' -> 0\n",
    "data['Label'] = data['Label'].replace({'s': 1, 'b': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b8533db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows that contain any -999 value\n",
    "data = data[~(data == -999).any(axis=1)] \n",
    "# Note: This removes approximately 73% of the dataset, leaving only about 27% of the original samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0affbf00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.910</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>41.928</td>\n",
       "      <td>197.760</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>67.435</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.240</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>89.744</td>\n",
       "      <td>13.550</td>\n",
       "      <td>59.149</td>\n",
       "      <td>116.344</td>\n",
       "      <td>2.636</td>\n",
       "      <td>284.584</td>\n",
       "      <td>-0.540</td>\n",
       "      <td>1.362</td>\n",
       "      <td>61.619</td>\n",
       "      <td>278.876</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>90.547</td>\n",
       "      <td>-2.412</td>\n",
       "      <td>-0.653</td>\n",
       "      <td>56.165</td>\n",
       "      <td>0.224</td>\n",
       "      <td>3.106</td>\n",
       "      <td>193.660</td>\n",
       "      <td>0.083414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>148.754</td>\n",
       "      <td>28.862</td>\n",
       "      <td>107.782</td>\n",
       "      <td>106.130</td>\n",
       "      <td>0.733</td>\n",
       "      <td>158.359</td>\n",
       "      <td>0.113</td>\n",
       "      <td>2.941</td>\n",
       "      <td>2.545</td>\n",
       "      <td>305.967</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>123.010</td>\n",
       "      <td>0.864</td>\n",
       "      <td>1.450</td>\n",
       "      <td>56.867</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-2.767</td>\n",
       "      <td>179.877</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>114.744</td>\n",
       "      <td>10.286</td>\n",
       "      <td>75.712</td>\n",
       "      <td>30.816</td>\n",
       "      <td>2.563</td>\n",
       "      <td>252.599</td>\n",
       "      <td>-1.401</td>\n",
       "      <td>2.888</td>\n",
       "      <td>36.745</td>\n",
       "      <td>239.804</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>76.773</td>\n",
       "      <td>-0.790</td>\n",
       "      <td>0.303</td>\n",
       "      <td>56.876</td>\n",
       "      <td>1.773</td>\n",
       "      <td>-2.079</td>\n",
       "      <td>165.640</td>\n",
       "      <td>0.307170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>141.481</td>\n",
       "      <td>0.736</td>\n",
       "      <td>111.581</td>\n",
       "      <td>174.075</td>\n",
       "      <td>1.955</td>\n",
       "      <td>364.344</td>\n",
       "      <td>-0.923</td>\n",
       "      <td>1.335</td>\n",
       "      <td>6.663</td>\n",
       "      <td>440.859</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>195.533</td>\n",
       "      <td>1.156</td>\n",
       "      <td>1.416</td>\n",
       "      <td>82.477</td>\n",
       "      <td>-0.798</td>\n",
       "      <td>-2.785</td>\n",
       "      <td>278.009</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249976</th>\n",
       "      <td>137.371</td>\n",
       "      <td>4.640</td>\n",
       "      <td>92.603</td>\n",
       "      <td>107.121</td>\n",
       "      <td>3.189</td>\n",
       "      <td>322.430</td>\n",
       "      <td>-2.384</td>\n",
       "      <td>2.149</td>\n",
       "      <td>2.755</td>\n",
       "      <td>225.261</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>85.132</td>\n",
       "      <td>1.991</td>\n",
       "      <td>-1.518</td>\n",
       "      <td>51.068</td>\n",
       "      <td>-1.197</td>\n",
       "      <td>-2.831</td>\n",
       "      <td>136.200</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249980</th>\n",
       "      <td>119.934</td>\n",
       "      <td>20.078</td>\n",
       "      <td>88.751</td>\n",
       "      <td>35.227</td>\n",
       "      <td>0.660</td>\n",
       "      <td>111.491</td>\n",
       "      <td>1.836</td>\n",
       "      <td>2.800</td>\n",
       "      <td>18.532</td>\n",
       "      <td>189.198</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>69.219</td>\n",
       "      <td>-1.064</td>\n",
       "      <td>1.118</td>\n",
       "      <td>43.719</td>\n",
       "      <td>-1.725</td>\n",
       "      <td>-2.756</td>\n",
       "      <td>112.938</td>\n",
       "      <td>0.018636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249985</th>\n",
       "      <td>126.151</td>\n",
       "      <td>29.023</td>\n",
       "      <td>95.258</td>\n",
       "      <td>152.684</td>\n",
       "      <td>1.000</td>\n",
       "      <td>163.066</td>\n",
       "      <td>-0.240</td>\n",
       "      <td>1.504</td>\n",
       "      <td>24.642</td>\n",
       "      <td>327.502</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>158.904</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.034</td>\n",
       "      <td>34.196</td>\n",
       "      <td>-0.599</td>\n",
       "      <td>-2.525</td>\n",
       "      <td>193.099</td>\n",
       "      <td>0.018636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249993</th>\n",
       "      <td>130.075</td>\n",
       "      <td>3.918</td>\n",
       "      <td>66.781</td>\n",
       "      <td>77.369</td>\n",
       "      <td>0.936</td>\n",
       "      <td>322.296</td>\n",
       "      <td>-0.207</td>\n",
       "      <td>3.102</td>\n",
       "      <td>49.937</td>\n",
       "      <td>610.482</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>155.864</td>\n",
       "      <td>-0.358</td>\n",
       "      <td>1.093</td>\n",
       "      <td>134.344</td>\n",
       "      <td>0.578</td>\n",
       "      <td>-2.215</td>\n",
       "      <td>546.066</td>\n",
       "      <td>0.001503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249994</th>\n",
       "      <td>217.020</td>\n",
       "      <td>47.156</td>\n",
       "      <td>62.824</td>\n",
       "      <td>127.953</td>\n",
       "      <td>0.295</td>\n",
       "      <td>119.437</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>2.318</td>\n",
       "      <td>3.628</td>\n",
       "      <td>242.586</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>141.752</td>\n",
       "      <td>0.237</td>\n",
       "      <td>3.126</td>\n",
       "      <td>32.423</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-1.137</td>\n",
       "      <td>174.176</td>\n",
       "      <td>0.064061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68114 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n",
       "0            138.470                       51.655        97.827    27.980   \n",
       "5             89.744                       13.550        59.149   116.344   \n",
       "6            148.754                       28.862       107.782   106.130   \n",
       "11           114.744                       10.286        75.712    30.816   \n",
       "23           141.481                        0.736       111.581   174.075   \n",
       "...              ...                          ...           ...       ...   \n",
       "249976       137.371                        4.640        92.603   107.121   \n",
       "249980       119.934                       20.078        88.751    35.227   \n",
       "249985       126.151                       29.023        95.258   152.684   \n",
       "249993       130.075                        3.918        66.781    77.369   \n",
       "249994       217.020                       47.156        62.824   127.953   \n",
       "\n",
       "        DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0                      0.910           124.711                2.666   \n",
       "5                      2.636           284.584               -0.540   \n",
       "6                      0.733           158.359                0.113   \n",
       "11                     2.563           252.599               -1.401   \n",
       "23                     1.955           364.344               -0.923   \n",
       "...                      ...               ...                  ...   \n",
       "249976                 3.189           322.430               -2.384   \n",
       "249980                 0.660           111.491                1.836   \n",
       "249985                 1.000           163.066               -0.240   \n",
       "249993                 0.936           322.296               -0.207   \n",
       "249994                 0.295           119.437               -0.014   \n",
       "\n",
       "        DER_deltar_tau_lep  DER_pt_tot  DER_sum_pt  ...  PRI_jet_num  \\\n",
       "0                    3.064      41.928     197.760  ...            2   \n",
       "5                    1.362      61.619     278.876  ...            3   \n",
       "6                    2.941       2.545     305.967  ...            2   \n",
       "11                   2.888      36.745     239.804  ...            3   \n",
       "23                   1.335       6.663     440.859  ...            2   \n",
       "...                    ...         ...         ...  ...          ...   \n",
       "249976               2.149       2.755     225.261  ...            2   \n",
       "249980               2.800      18.532     189.198  ...            2   \n",
       "249985               1.504      24.642     327.502  ...            2   \n",
       "249993               3.102      49.937     610.482  ...            3   \n",
       "249994               2.318       3.628     242.586  ...            2   \n",
       "\n",
       "        PRI_jet_leading_pt  PRI_jet_leading_eta  PRI_jet_leading_phi  \\\n",
       "0                   67.435                2.150                0.444   \n",
       "5                   90.547               -2.412               -0.653   \n",
       "6                  123.010                0.864                1.450   \n",
       "11                  76.773               -0.790                0.303   \n",
       "23                 195.533                1.156                1.416   \n",
       "...                    ...                  ...                  ...   \n",
       "249976              85.132                1.991               -1.518   \n",
       "249980              69.219               -1.064                1.118   \n",
       "249985             158.904                0.401                0.034   \n",
       "249993             155.864               -0.358                1.093   \n",
       "249994             141.752                0.237                3.126   \n",
       "\n",
       "        PRI_jet_subleading_pt  PRI_jet_subleading_eta  PRI_jet_subleading_phi  \\\n",
       "0                      46.062                   1.240                  -2.475   \n",
       "5                      56.165                   0.224                   3.106   \n",
       "6                      56.867                   0.131                  -2.767   \n",
       "11                     56.876                   1.773                  -2.079   \n",
       "23                     82.477                  -0.798                  -2.785   \n",
       "...                       ...                     ...                     ...   \n",
       "249976                 51.068                  -1.197                  -2.831   \n",
       "249980                 43.719                  -1.725                  -2.756   \n",
       "249985                 34.196                  -0.599                  -2.525   \n",
       "249993                134.344                   0.578                  -2.215   \n",
       "249994                 32.423                  -0.058                  -1.137   \n",
       "\n",
       "        PRI_jet_all_pt    Weight  Label  \n",
       "0              113.497  0.002653      1  \n",
       "5              193.660  0.083414      0  \n",
       "6              179.877  0.002653      1  \n",
       "11             165.640  0.307170      0  \n",
       "23             278.009  0.001503      1  \n",
       "...                ...       ...    ...  \n",
       "249976         136.200  0.001503      1  \n",
       "249980         112.938  0.018636      1  \n",
       "249985         193.099  0.018636      1  \n",
       "249993         546.066  0.001503      1  \n",
       "249994         174.176  0.064061      0  \n",
       "\n",
       "[68114 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccadfd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features (X) and target (y)\n",
    "X = data.drop(columns=['Label']) \n",
    "y = data['Label']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4265d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train/test split (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,        \n",
    "    stratify=y,             # Preserve the proportion of class labels\n",
    "    random_state=42        \n",
    ")\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dfbbdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a80e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib  # Import for saving/loading models\n",
    "\n",
    "# Define the grid of hyperparameters to search over during GridSearchCV\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [\n",
    "        (64, 32),      # Small network architecture: input(30) → 64 → 32 → output(1)\n",
    "        (100, 50),     # Medium network: 30 → 100 → 50 → 1\n",
    "        (128, 64),     # Large network: 30 → 128 → 64 → 1\n",
    "        (100, 25),     # Asymmetric network: 30 → 100 → 25 → 1\n",
    "    ],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],        # L2 regularization parameter to reduce overfitting\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],   # Initial learning rates to try\n",
    "}\n",
    "\n",
    "# Fixed parameters for the MLPClassifier that won't be tuned in the grid search\n",
    "fixed_params = {\n",
    "    'activation': 'relu',         # Activation function: ReLU (fast and effective)\n",
    "    'solver': 'adam',             # Optimization algorithm: Adam optimizer (usually best choice)\n",
    "    'max_iter': 150,              # Max number of epochs (full passes over training data), reduced for speed\n",
    "    'early_stopping': True,       # Stop training early if no improvement on validation set\n",
    "    'random_state': 42            # Fix seed for reproducibility\n",
    "}\n",
    "\n",
    "# Initialize the base MLPClassifier with fixed parameters\n",
    "mlp_base = MLPClassifier(**fixed_params)\n",
    "\n",
    "# Set up grid search with 3-fold cross-validation to find best hyperparameters\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=mlp_base,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,                    # 3-fold CV to balance speed and reliability\n",
    "    scoring='accuracy',      # Optimize for accuracy metric\n",
    "    n_jobs=-1,               # Use all CPU cores available\n",
    "    verbose=2                # Show detailed progress during training\n",
    ")\n",
    "\n",
    "# Fit grid search on the scaled training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best cross-validation score obtained\n",
    "print(f\" Best CV score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Print the best hyperparameters found by grid search\n",
    "print(f\" Best hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Print a summary of the optimal network architecture and hyperparameters\n",
    "print(f\"Network architecture: {X_train.shape[1]} → {best_params['hidden_layer_sizes'][0]} → {best_params['hidden_layer_sizes'][1]} → 1\")\n",
    "print(f\"L2 regularization (alpha): {best_params['alpha']}\")\n",
    "print(f\"Initial learning rate: {best_params['learning_rate_init']}\")\n",
    "print(f\"Activation function: relu (fixed)\")\n",
    "print(f\"Solver: adam (fixed)\")\n",
    "\n",
    "# Retrieve the best trained model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Save the trained model to disk for later use\n",
    "joblib.dump(best_model, 'best_mlp_model.pkl')\n",
    "print(\"Best model saved to 'best_mlp_model.pkl'\")\n",
    "\n",
    "# Later, you can load the model like this:\n",
    "# loaded_model = joblib.load('best_mlp_model.pkl')\n",
    "# And use it to predict or evaluate on the test set\n",
    "# For example:\n",
    "# y_pred = loaded_model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d99e838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the model with 2 hidden layers\n",
    "def build_model(n_neurons_1=64, n_neurons_2=32, learning_rate=0.001, l2_reg=1e-4, activation='relu'):\n",
    "    # Define a sequential model\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Add input layer + first hidden layer\n",
    "    model.add(tf.keras.Input(shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(tf.keras.layers.Dense(n_neurons_1, activation=activation,\n",
    "                                    kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    \n",
    "    # Add second hidden layer\n",
    "    model.add(tf.keras.layers.Dense(n_neurons_2, activation=activation,\n",
    "                                    kernel_regularizer=regularizers.l2(l2_reg)))\n",
    "    \n",
    "    # Add output layer for binary classification\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model with Adam optimizer and binary crossentropy loss\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594f880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: n1=32, n2=32, lr=0.001, l2=0.01, batch=32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Build and train model\u001b[39;00m\n\u001b[1;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(n_neurons_1\u001b[38;5;241m=\u001b[39mn1, n_neurons_2\u001b[38;5;241m=\u001b[39mn2,\n\u001b[1;32m     33\u001b[0m                     learning_rate\u001b[38;5;241m=\u001b[39mlr, l2_reg\u001b[38;5;241m=\u001b[39ml2)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Evaluate on validation fold\u001b[39;00m\n\u001b[1;32m     37\u001b[0m _, acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_val, y_val, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/myenv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_neurons_1': [32, 64],\n",
    "    'n_neurons_2': [32, 64],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'l2_reg': [0.01, 0.001, 0.0001],\n",
    "    'batch_size': [32, 64, 128]\n",
    "}\n",
    "\n",
    "# 5-fold stratified cross-validation\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Track the best model performance\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "\n",
    "# Grid search loop over all combinations of hyperparameters\n",
    "for n1 in param_grid['n_neurons_1']:\n",
    "    for n2 in param_grid['n_neurons_2']:\n",
    "        for lr in param_grid['learning_rate']:\n",
    "            for l2 in param_grid['l2_reg']:\n",
    "                for batch_size in param_grid['batch_size']:\n",
    "                    accuracies = []\n",
    "                    print(f\"Testing: n1={n1}, n2={n2}, lr={lr}, l2={l2}, batch={batch_size}\")\n",
    "                    \n",
    "                    # Cross-validation loop\n",
    "                    for train_idx, val_idx in kf.split(X_train_scaled, y_train):\n",
    "                        X_tr, X_val = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "                        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "                        \n",
    "                        # Build and train model\n",
    "                        model = build_model(n_neurons_1=n1, n_neurons_2=n2,\n",
    "                                            learning_rate=lr, l2_reg=l2)\n",
    "                        model.fit(X_tr, y_tr, epochs=20, batch_size=batch_size, verbose=0)\n",
    "                        \n",
    "                        # Evaluate on validation fold\n",
    "                        _, acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "                        accuracies.append(acc)\n",
    "                    \n",
    "                    # Compute mean accuracy across folds\n",
    "                    mean_acc = np.mean(accuracies)\n",
    "                    print(f\"Mean accuracy: {mean_acc:.4f}\")\n",
    "                    \n",
    "                    # Save best model if accuracy is improved\n",
    "                    if mean_acc > best_acc:\n",
    "                        best_acc = mean_acc\n",
    "                        best_params = {\n",
    "                            'n_neurons_1': n1,\n",
    "                            'n_neurons_2': n2,\n",
    "                            'learning_rate': lr,\n",
    "                            'l2_reg': l2,\n",
    "                            'batch_size': batch_size\n",
    "                        }\n",
    "\n",
    "# Print best results\n",
    "print(\"Best parameters found:\", best_params)\n",
    "print(f\"Best cross-validation accuracy: {best_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
