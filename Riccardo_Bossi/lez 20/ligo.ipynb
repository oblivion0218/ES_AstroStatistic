{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c201cc",
   "metadata": {},
   "source": [
    "## Time to get your hands dirty! Can a computer learn if we're going to detect gravitational waves?\n",
    "\n",
    "This episode of \"time to get your hands dirty\" is about something I studied carefully in the past: gravitational-wave selection effects. This is one the LIGO interferometers:\n",
    "\n",
    "![](https://www.ligo.caltech.edu/system/news_items/images/53/page/Virgo_aerial_view_01.jpg?1506530275)\n",
    "\n",
    "\n",
    "All experiments have selection effects. Some sources are easier to detect than others which distorts the population of sources we observe (this crucial in astronomy! Surveys are typically flux limited). \n",
    "In order to decided if a feature in the observed population of objects is telling us something new about reality, we need to understand and model our selection effects (for instance: it would be wrong to say that all stars are close by just because we can't observe those that are very far!). In observational astronomy, this is known as [Malmquist bias](https://en.wikipedia.org/wiki/Malmquist_bias) and was first formulated in 1922.\n",
    " \n",
    "**The goal here is to machine-learn the LIGO detectability: can we *predict* if a gravitational-wave source will be detected?**  \n",
    "\n",
    "[This dataset](https://github.com/dgerosa/pdetclassifier/releases/download/v0.2/sample_2e7_design_precessing_higherordermodes_3detectors.h5) contains simulated gravitational-wave signals from merging black holes (careful the file size is >1 GB). If you've never seen them, the [.h5 format](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) is a highly optimized storage strategy for large datasets. It's amazing. In python, you can read it with `h5py`.\n",
    "\n",
    "In particular, each source has the following features:\n",
    "- `mtot`: the total mass of the binary\n",
    "- `q`: the mass ratio\n",
    "- `chi1x`, `chi1y`, `chi1z`, `chi2x`, `chi2y`, `chi2z`: the components of the black-hole spins in a suitable reference frame.\n",
    "- `ra`, `dec`: the location of the source in the sky\n",
    "- `iota`: the inclination of the orbital plane'\n",
    "- `psi`: the polarization angle (gravitational waves have two polarization states much like light)\n",
    "- `z`: the redshift\n",
    "\n",
    "The detectability is defined using the `snr` (signal-to-noise ratio) computed with a state-of-the-art model of the LIGO/Virgo detector network. Some (many?) of you will have studied this in the gravitational-wave class; [see here](https://arxiv.org/abs/1908.11170) for a nice write-up. All you need to know now is that we threshold the `snr` values and assume that LIGO will (not) see a source if `snr`>12 (`snr`<12). The resulting 0-1 labels are reported in the `det` attribute in the dataset.\n",
    "\n",
    "Today's task is to train a classifier (you decide which one!) and separate sources that are detectables from those that aren't. \n",
    "\n",
    "Be creative! This is a challenge! Let's see who gets the  higher completeness and/or the smaller contamination (on a validation set, of course, careful with overfitting here).\n",
    "\n",
    "*Tips*:\n",
    "- You can downsample the data for debugging purposes\n",
    "- You can also use only some of the features.\n",
    "- Plot ROC curves\n",
    "- **Important** Don't use `snr` as feature in your classifer (that's the answer...)\n",
    "\n",
    "\n",
    "### Other ideas (optional)\n",
    "\n",
    "- Using the same data, we could run a regressor on `snr` instead of a classifier on `det`. We can then threshold the predictions (instead of tresholding the data like we're doing now). Would this give a better performance?\n",
    "\n",
    "- How about trying to reduce the dimensionality of the dataset with a PCA-type algorithm to ease the classification problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32164d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chiavi nel file:\n",
      "['chi1x', 'chi1y', 'chi1z', 'chi2x', 'chi2y', 'chi2z', 'dec', 'det', 'iota', 'mtot', 'psi', 'q', 'ra', 'snr', 'z']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Apri il file in modalitÃ  lettura\n",
    "with h5py.File('../../../dati_ligo.h5', 'r') as file:\n",
    "    # Lista dei dataset/chiavi principali\n",
    "    print(\"Chiavi nel file:\")\n",
    "    print(list(file.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc056a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "with h5py.File('dati_ligo.h5', 'r') as file:\n",
    "    keys = ['chi1x', 'chi1y', 'chi1z', 'chi2x', 'chi2y', 'chi2z', 'dec', 'det', 'iota',\n",
    "            'mtot', 'psi', 'q', 'ra', 'snr', 'z']\n",
    "    \n",
    "    data_list = []\n",
    "    for key in tqdm(keys, desc=\"Caricamento dati\"):\n",
    "        data_list.append(file[key][:])\n",
    "        \n",
    "    data = np.stack(data_list, axis=1)\n",
    "\n",
    "#puizia dati\n",
    "initial_shape = data.shape\n",
    "mask_valid = ~np.isnan(data).any(axis=1) & ~(data == -999).any(axis=1)\n",
    "clean_data = data[mask_valid]\n",
    "final_shape = clean_data.shape\n",
    "\n",
    "print(f\"\\nRighe totali prima della pulizia: {initial_shape[0]}\")\n",
    "print(f\"Righe rimosse: {initial_shape[0] - final_shape[0]}\")\n",
    "print(f\"Righe rimanenti: {final_shape[0]}\")\n",
    "\n",
    "#pca\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(data)\n",
    "\n",
    "#plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], s=10, alpha=0.7)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"PCA delle caratteristiche\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
