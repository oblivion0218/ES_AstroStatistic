{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816324f2",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 2** - Probability & Statistic I </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03de5df3",
   "metadata": {},
   "source": [
    "- PDF, CDF, quantile\n",
    "- Real and empirical distributions\n",
    "- Errors: heteroscedastic and homoscedastic\n",
    "- Kolmogorov axioms and probability\n",
    "- Bayes’ theorem\n",
    "- Transformations of random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35648beb",
   "metadata": {},
   "source": [
    "### **Probability Density Function (PDF), Cumulative Distribution Function (CDF), and Quantile**\n",
    "\n",
    "- **PDF (Probability Density Function)**: Describes the probability for a continuous variable to take a specific value. The area under the PDF over an interval gives the probability of the variable falling within that interval.\n",
    "- **CDF (Cumulative Distribution Function)**: It is obtained by integrating the PDF from - infinity up to a certain values X. Gives the probability that a random variable is less than or equal to a certain value. \n",
    "\n",
    "$$\n",
    "H(x) = \\int_{-\\infty}^{x} h(x')\\, dx'\n",
    "$$\n",
    "\n",
    "\n",
    "- **Quantile**: it's the inverse of the CDF. The value below which a certain percentage of observations fall. For example, the 0.25 quantile (or 25th percentile) is the value below which 25% of the data lie.\n",
    "\n",
    "---\n",
    "\n",
    "### **Empirical and Theoretical Distributions**\n",
    "\n",
    "- **Theoretical Distribution**: A probability distribution derived from a known mathematical model (e.g., Normal, Poisson).\n",
    "- **Empirical Distribution**: Based on observed data. It approximates the distribution of a dataset and is typically represented by the empirical CDF or histogram.\n",
    "- Empirical distributions are used when the true distribution is unknown or difficult to model.\n",
    "\n",
    "---\n",
    "\n",
    "### **Homoscedastic and Heteroscedastic Errors**\n",
    "\n",
    "- **Homoscedasticity**: The variance of the errors is constant.\n",
    "- **Heteroscedasticity**: The error variance changes with the data\n",
    "\n",
    "---\n",
    "\n",
    "### **Kolmogorov's Axioms and Probability**\n",
    "\n",
    "Kolmogorov formalized the foundation of probability with three axioms:\n",
    "\n",
    "1. **Non-negativity**: For any event A, the probability is non-negative:  \n",
    "   \\( P(A) >= 0 \\)\n",
    "2. **Normalization**: The probability of the entire sample space is 1:  \n",
    "   \\( P($\\Omega$) = 1 \\)\n",
    "3. **Additivity**: For any two mutually exclusive events A and B:  \n",
    "   \\( P(A $\\cup$ B) = P(A) + P(B) \\)\n",
    "\n",
    "These axioms form the basis of modern probability theory.\n",
    "\n",
    "---\n",
    "\n",
    "### **Bayes' Theorem**\n",
    "\n",
    "Bayes' Theorem updates the probability of a hypothesis based on new evidence:\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "-  P(A|B) : Posterior probability (updated belief)  \n",
    "-  P(B|A) : Likelihood of observing B given A  \n",
    "-  P(A) : Prior probability of A  \n",
    "-  P(B) : Marginal probability of B. We can write the marginal probability of x as:   $ p(x) = \\int p(x,y) dy = \\int p(x|y)p(y)dy$\n",
    "\n",
    "Used in many fields like medicine, machine learning, and decision theory.\n",
    "\n",
    "---\n",
    "\n",
    "### **Transformations of Random Variables**\n",
    "\n",
    "Transforming a random variable means applying a function to it, creating a new variable.\n",
    "\n",
    "- **Example**: Let \\( X \\) be a random variable and \\( Y = g(X) \\) a transformation.\n",
    "- To find the **distribution of \\( Y \\)**:\n",
    "  - If \\( X \\) is continuous with PDF \\( $f_X$ \\) and \\( g \\) is invertible, then:\n",
    "\n",
    "$$\n",
    "f_Y(y) = f_X(g^{-1}(y)) \\cdot \\left| \\frac{d}{dy} g^{-1}(y) \\right|\n",
    "$$\n",
    "\n",
    "- This is used to derive distributions of functions of random variables (e.g., squares, sums, logarithms).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa401bbc",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 3** - Probability & Statistic II </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d9b6e4",
   "metadata": {},
   "source": [
    "- Monte Carlo integration (crude / hit-or-miss)  \n",
    "- Mean, median, and expected value  \n",
    "- Standard deviation, MAD1, variance, MAD2, quantile region, interquantile range, mode  \n",
    "- Skewness  \n",
    "- Kurtosis  \n",
    "- Statistics of the PDF and sample; Bessel’s correction  \n",
    "- Uncertainties of estimators  \n",
    "- PDFs: uniform, Gaussian, log-normal, chi-squared, Poisson  \n",
    "- Importance sampling  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dd6cd1",
   "metadata": {},
   "source": [
    "### **Monte Carlo Integration (Crude and Hit-or-Miss)**\n",
    "\n",
    "- **Monte Carlo integration** uses random sampling to approximate definite integrals.\n",
    "- **Crude Monte Carlo**:  \n",
    "  Estimate the integral $\\int_a^b f(x) \\, dx$ by sampling $x_i \\sim \\mathcal{U}(a, b)$ and computing:  \n",
    "  $$\n",
    "  I \\approx (b - a) \\cdot \\frac{1}{N} \\sum_{i=1}^N f(x_i)\n",
    "  $$\n",
    "- **Hit-or-Miss method**:  \n",
    "  Sample uniformly in a rectangle that encloses the graph of $f(x)$.  \n",
    "  The integral is approximated by the fraction of points that fall below the curve times the area of the rectangle.\n",
    "\n",
    "---\n",
    "\n",
    "### **Mean, Median, Expected Value, and Mode**\n",
    "\n",
    "KEEP ATTENTION AT THE DIFFERENT USE OF $\\bar{x}$ AND $\\mu$\n",
    "\n",
    "- **Mean**: Arithmetic average of a dataset. $\\mu = \\mathbb{E}[X]$, Where X will denote an entire dataset.\n",
    "- **Median**: Middle value when data are ordered. Less sensitive to outliers.\n",
    "- **Expected value** $\\mathbb{E}[X]$ : Theoretical mean of a random variable. For continuous variables:  \n",
    "  $$\n",
    "  \\mathbb{E}[X] = \\int x f(x) \\, dx\n",
    "  $$\n",
    "- **Mode**: Most frequent value in a dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### **Standard Deviation, Variance, MAD, Quantiles, and IQR**\n",
    "\n",
    "- **Variance** (2nd-order moment):  \n",
    "  $$\n",
    "  \\sigma^2 = \\text{Var}(X) = \\mathbb{E}[(X - \\mu)^2] = \\int_{-\\infty}^{+\\infty}(x - \\mu)^2 f(x) \\, dx\n",
    "  $$\n",
    "- **Standard Deviation** $\\sigma$: Measures spread around the mean. It is the square root of the variance:\n",
    "  $$\n",
    "  \\sigma = \\sqrt{\\text{Var}(X)} = \\sqrt{\\sigma^2}\n",
    "  $$\n",
    "- **MAD_1 (Mean Absolute Deviation)**:  \n",
    "  $$\n",
    "  \\text{MAD}_1 = \\frac{1}{N} \\sum_{i=1}^N |x_i - \\bar{x}|\n",
    "  $$\n",
    "  Note: this is not differentiable at  x = 0 , so it's sometimes avoided in optimization.\n",
    "- **MAD_2 (Median Absolute Deviation)**:  \n",
    "  $$\n",
    "  \\text{MAD}_2 = \\frac{1}{N} \\sum_{i=1}^N |x_i - M|\n",
    "  $$\n",
    "  where M is the median.\n",
    "- **Quantile region**: Range containing a central portion of the distribution (e.g., 95% interval).\n",
    "- **Interquantile Range (IQR)**:  \n",
    "  $$\n",
    "  \\text{IQR} = Q_{75} - Q_{25}\n",
    "  $$\n",
    "  Contains the central 50% of the data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Skewness and Kurtosis**\n",
    "\n",
    "- **Skewness**: Measures asymmetry of a distribution (3rd-order moment).  \n",
    "  - Positive skew: tail to the right.  \n",
    "  - Negative skew: tail to the left.  \n",
    "  - Formula:\n",
    "    $$\n",
    "    \\text{Skewness} = \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{x_i - \\bar{x}}{\\sigma} \\right)^3\n",
    "    $$\n",
    "- **Kurtosis**: Measures how likely extreme values (far from the mean) are (4th-order moment).  \n",
    "  - High kurtosis: heavy tails.  \n",
    "  - Low kurtosis: light tails.  \n",
    "  - Normal distribution has kurtosis = 3.  \n",
    "  - Formula:\n",
    "    $$\n",
    "    \\text{Kurtosis} = \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{x_i - \\bar{x}}{\\sigma} \\right)^4\n",
    "    $$\n",
    "\n",
    "---\n",
    "\n",
    "### **PDF vs Sample Statistics and Bessel’s Correction**\n",
    "\n",
    "- **PDF statistics**: Theoretical values computed from a probability distribution.\n",
    "- **Sample statistics**: Estimates of those values based on observed data.\n",
    "- **Bessel’s correction**: When estimating variance from a sample, use:\n",
    "  $$\n",
    "  s^2 = \\frac{1}{N - 1} \\sum_{i=1}^N (x_i - \\bar{x})^2\n",
    "  $$\n",
    "  This gives an **unbiased estimate** of the population variance.  \n",
    "  You can skip Bessel’s correction only when N is large.\n",
    "\n",
    "---\n",
    "\n",
    "### **Uncertainties of Estimators**\n",
    "\n",
    "When we compute estimators like the mean, variance, or IQR from a sample, there’s **uncertainty** because we have only a finite number of points. This is captured by the **standard error (SE)**.\n",
    "\n",
    "- **Sample Mean**:\n",
    "  $$\n",
    "  \\text{SE}(\\bar{x}) = \\frac{\\sigma}{\\sqrt{N}}\n",
    "  $$\n",
    "\n",
    "- **Sample Standard Deviation** and **Variance**:\n",
    "  $$\n",
    "  \\text{SE}(\\sigma) \\approx \\frac{\\sigma}{\\sqrt{2N}}, \\quad \\text{SE}(\\sigma^2) = \\frac{\\sigma^2}{2N}\n",
    "  $$\n",
    "\n",
    "- **Interquartile Range (IQR)**:\n",
    "  $$\n",
    "  \\text{SE}(\\text{IQR}) \\approx \\frac{1.58 \\times \\text{IQR}}{\\sqrt{N}}\n",
    "  $$\n",
    "\n",
    "General rule: **more data → smaller standard error**, since uncertainty scales as $ \\frac{1}{\\sqrt{N}}$.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **PDFs: Uniform, Gaussian, Log-Normal, Chi-Squared, Poisson**\n",
    "\n",
    "- **Uniform**: All values in an interval have equal probability.  \n",
    "  $$\n",
    "  f(x) = \\frac{1}{b - a}      \\text{    for   } x \\in [a, b]\n",
    "  $$\n",
    "\n",
    "  this distribution has $\\sigma = \\frac{b-a}{\\sqrt{12}}$\n",
    "- **Gaussian (Normal)**: Curve defined by mean $\\mu$ and std $\\sigma$.  \n",
    "  $$\n",
    "  f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\, e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\n",
    "  $$\n",
    "  - The convolution of two gaussian is a gaussian too.\n",
    "  - It's the queen of distribution , because most natural process follow this shape and it's quite easy to use.\n",
    "  - $1\\sigma$ = 68% // $2\\sigma$ = 95%\n",
    "\n",
    "- **Log-Normal**: $X \\sim \\text{LogNormal}$ means $\\ln X \\sim \\text{Normal}$.\n",
    "- **Chi-squared** ($\\chi^2$):  \n",
    "  If we define standardized variables as  \n",
    "  $$\n",
    "  z_i = \\frac{x_i - \\mu}{\\sigma},\n",
    "  $$  \n",
    "  then the sum of their squares  \n",
    "  $$\n",
    "  Q = \\sum_{i=1}^N z_i^2\n",
    "  $$  \n",
    "  follows a **chi-squared distribution** with $K$ degrees of freedom.\n",
    "\n",
    "  The number of degrees of freedom $K$ is equal to the number of **independent** data points used in the sum.\n",
    "\n",
    "- **Poisson**: Discrete distribution for count data.  \n",
    "  $$\n",
    "  P(k; \\mu) = \\frac{\\mu^k e^{-\\mu}}{k!}\n",
    "  $$\n",
    "  - Where: $\\mu$ is the mean, K is the number of events occouring\n",
    "  - Known as \"law of rare events\"\n",
    "\n",
    "---\n",
    "\n",
    "### **Importance Sampling**\n",
    "\n",
    "- Hit or miss and Crude MC, are inefficient if the integrand has some null zone, or even if is really extendended... that's beacuse this 2 methode use the uniform distribution.\n",
    "- Instead of sampling from the uniform, sample from a **proposal distribution** $g(x)$ \n",
    "- Best when $g(x)$ is close to the shape of $f(x)$.\n",
    "- Reduces variance and computational cost if the $g(x)$ it's well chosen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea58c2c4",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 4** - Probability & Statistic III </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaca67",
   "metadata": {},
   "source": [
    "- Central Limit Theorem  \n",
    "- Law of Large Numbers  \n",
    "- Multidimensional PDFs (mean, sigma x and y, covariance, correlation coefficient, principal axes, 2D confidence level)  \n",
    "- Correlation vs causation (Pearson, Spearman, Kendall)  \n",
    "- Rejection sampling  \n",
    "- Inverse sampling  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc59594",
   "metadata": {},
   "source": [
    "### **Central Limit Theorem (CLT)**\n",
    "\n",
    "The CLT states that the sum (or mean) of a large number of independent, identically distributed random variables tends to follow a **normal distribution**, regardless of the original distribution.\n",
    "\n",
    "---\n",
    "\n",
    "### **Law of Large Numbers (LLN)**\n",
    "\n",
    "- The LLN states that as the number of observations $N$ increases, the sample mean $\\bar{x}$ converges to the true mean $\\mu$, this is also valid fot the variance:\n",
    "  $$\n",
    "  \\lim_{N \\to \\infty} \\bar{x} = \\mu \\quad \\lim_{N \\to \\infty} s = \\sigma\n",
    "  $$\n",
    "- This is a statement about convergence **in probability**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Multidimensional PDFs**\n",
    "\n",
    "- In 2D, the joint distribution can be described by:\n",
    "  - **Mean vector**:  \n",
    "    $$\n",
    "    \\vec{\\mu} = (\\mu_x, \\mu_y)\n",
    "    $$\n",
    "\n",
    "  - **Covariance matrix**:  \n",
    "    $$\n",
    "    \\Sigma = \\begin{pmatrix}\n",
    "    \\sigma_x^2 & \\text{cov}(x, y) \\\\\n",
    "    \\text{cov}(y, x) & \\sigma_y^2\n",
    "    \\end{pmatrix}\n",
    "    $$\n",
    "    The two off diagonal values are equal to 0 only if x & y are totaly uncorrelated\n",
    "\n",
    "  - **Correlation coefficient**:  \n",
    "    $$\n",
    "    \\rho = \\frac{\\text{cov}(x, y)}{\\sigma_x \\sigma_y}\n",
    "    $$\n",
    "    Express the percentual of correlation between the 2 variable\n",
    "\n",
    "  - **Principal axes**: determined by the eigenvectors of $\\Sigma$; note that the correlation vanish in this system by definition.\n",
    "  - **2D Confidence Ellipses**: regions where the joint probability is constant, keep attention, for each dimension the number of sigma has a different meaning: $1\\sigma = 39$% in 2 dimension! I can impose 68% for the similitude with 1D, but it's not $1\\sigma$.\n",
    "\n",
    "---\n",
    "\n",
    "### **Correlation vs Causation**\n",
    "\n",
    "Correlation does not imply causation!\n",
    "Just because the sun burns our skin and also makes us thirsty, it doesn't mean that thirst causes sunburn!\n",
    "\n",
    "- **Pearson's correlation** (r) : Measures linear correlation between 2 different dataset; it's a value between -1 and 1, the 2 are uncorrelated only if r = 0.\n",
    "It has 2 problems:\n",
    "  - it's susceptible at the outliars\n",
    "  - doesn't count the error\n",
    "\n",
    "- **Spearman's rho**: Measures monotonic (rank-based) correlation.\n",
    "- **Kendall's tau**: Measures ordinal association between two variables.\n",
    "\n",
    "---\n",
    "\n",
    "### **Rejection Sampling**\n",
    "\n",
    "Rejection sampling is a method to generate random samples from a complex distribution $p(x)$, using a simpler proposal distribution $q(x)$.\n",
    "\n",
    "The procedure works as follows:\n",
    "\n",
    "1. **Choose a proposal distribution** $q(x)$ from which it's easy to sample (often a uniform distribution).  \n",
    "   Make sure it's \"wide enough\" to cover the shape of $p(x)$, including its tails.\n",
    "\n",
    "2. **Find a constant** $M$ such that for all $x$:\n",
    "   $$\n",
    "   p(x) \\leq M q(x)\n",
    "   $$\n",
    "   This ensures the proposal dominates the target distribution.\n",
    "\n",
    "3. **Generate a candidate sample** $x $ from $q(x)$.\n",
    "\n",
    "4. **Draw a random number** $u $ from $ \\mathcal{U}(0, 1)$.\n",
    "\n",
    "5. **Accept or reject**:\n",
    "   - Accept $x$ if  \n",
    "     $$\n",
    "     u < \\frac{p(x)}{M q(x)}\n",
    "     $$\n",
    "   - Otherwise, reject $x$ and go back to step 3.\n",
    "\n",
    "The set of accepted $x$ values will follow the target distribution $p(x)$.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Inverse Transform Sampling**\n",
    "\n",
    "- Used to sample from a distribution with known CDF $F(x)$ and Quantile.\n",
    "- Steps:\n",
    "  1. Sample $u$ from  ${U}(0, 1)$.\n",
    "  2. Compute $x = F^{-1}(u)$.\n",
    "Normalizarion here are rellly important.\n",
    "you can retrive the quantile and the CDF by numerically solution if you are not able to do in by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012b4cd6",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 5** - Frequentist Inference I </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668bbc14",
   "metadata": {},
   "source": [
    "- Population  \n",
    "- Sample  \n",
    "- Statistics  \n",
    "- Estimators  \n",
    "- Uncertainties and intervals  \n",
    "- Frequentist vs Bayesian  \n",
    "- Maximum Likelihood Estimator (MLE)  \n",
    "- Properties of estimators  \n",
    "- Likelihood  \n",
    "- Chi-squared  \n",
    "- Minimization  \n",
    "- Mean and error of MLE with heteroscedastic and homoscedastic errors  \n",
    "- Non-Gaussian likelihoods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b71a25",
   "metadata": {},
   "source": [
    "### **Population, Sample, Statistic, Estimators, Uncertainty and Intervals**\n",
    "\n",
    "- A **population** is the full set of data or measurements we are interested in.\n",
    "- A **sample** is a subset of the population, used to infer properties of the whole.\n",
    "- A **statistic** is a function of the sample (e.g. the sample mean $\\bar{x}$).\n",
    "- An **estimator** is a rule or formula to estimate population parameters from the sample.\n",
    "- All estimators have **uncertainties** due to random sampling.\n",
    "- A **confidence interval**, gives a range likely to contain the true value.\n",
    "\n",
    "---\n",
    "\n",
    "### **Frequentist vs Bayesian**\n",
    "\n",
    "- **Frequentist**: Probability is extract from the frequency of events. Parameters are fixed, data are random.\n",
    "Into Frequentist inference we have confidence levels,.\n",
    "- **Bayesian**: Probability expresses belief or uncertainty about what we know. Parameters have distributions while data are fixed. In Bayesian inference we have credible regions derive from posterior distribution of the parameters.\n",
    "\n",
    "\n",
    "- Bayesian statistic it's hold by the **Bayes’ theorem**:\n",
    "  $$\n",
    "  P(\\theta | \\text{data}) = \\frac{P(\\text{data} | \\theta) \\cdot P(\\theta)}{P(\\text{data})}\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "### **Maximum Likelihood Estimator (MLE)**\n",
    "\n",
    "- The **MLE** is the value of the parameter $\\theta$ that **maximizes the likelihood** of the observed data:\n",
    "  $$\n",
    "  \\hat{\\theta}_{\\text{MLE}} = \\arg \\max_\\theta \\mathcal{L}(\\theta)\n",
    "  $$\n",
    "- It's usefull in both frequentist e bayesian approach\n",
    "- **Remember**: the **likelihood** is defined as the product of the probabilities (or probability densities) of the observed data, assuming a given model or parameter value.\n",
    "\n",
    "  For independent data points $x_1, x_2, ..., x_N$:\n",
    "\n",
    "  $$\n",
    "  \\mathcal{L}(\\theta) = \\prod_{i=1}^{N} p(x_i \\mid \\theta)\n",
    "  $$\n",
    "\n",
    "  Where:\n",
    "  - $\\mathcal{L}(\\theta)$ is the likelihood function,\n",
    "  - $p(x_i \\mid \\theta)$ is the probability (or density) of observing $x_i$ given parameter $\\theta$,\n",
    "  - The product assumes all $x_i$ are independent.\n",
    "\n",
    "  Often, we work with the **log-likelihood**:\n",
    "  $$\n",
    "  \\log \\mathcal{L}(\\theta) = \\sum_{i=1}^{N} \\log p(x_i \\mid \\theta)\n",
    "  $$\n",
    "  which is easier to compute and optimize.\n",
    "\n",
    "---\n",
    "\n",
    "### **Properties of Estimators**\n",
    "\n",
    "- **Unbiasedness**: $\\mathbb{E}[\\hat{\\theta}] = \\theta$\n",
    "- **Consistency**: $\\hat{\\theta} \\to \\theta$ as $N \\to \\infty$\n",
    "- **Efficiency**: Minimum possible variance (called Cramer-Rao bound)\n",
    "\n",
    "---\n",
    "\n",
    "### **Likelihood, Chi-squared and Minimization**\n",
    "\n",
    "- The **likelihood** $\\mathcal{L}(\\theta)$ is the probability of the data given parameters.\n",
    "- If we infere that the process has a gaussian distribution the Likelihood will follow the $\\exp(-\\chi^2/2)$\n",
    "- In Gaussian cases, maximizing the log-likelihood is equivalent to **minimizing the chi-squared**:\n",
    "  $$\n",
    "  \\chi^2 = \\sum_{i=1}^N \\left( \\frac{x_i - f(x_i; \\theta)}{\\sigma_i} \\right)^2\n",
    "  $$\n",
    "- Minimizing $\\chi^2$ gives the best-fit parameters.\n",
    "- The MLE method tell us to think the likelihood as a function of the (unknown) model parameters, and by minimizing the $\\chi^2$, we will find the values that maximize the values of the likelihood.\n",
    "\n",
    "---\n",
    "\n",
    "### **Mean and MLE Error: Homoscedastic vs Heteroscedastic**\n",
    "\n",
    "- **Homoscedastic**: All data points have the same uncertainty $\\sigma$. We Will use the mean:\n",
    "    $$\n",
    "    \\bar{x} = \\frac{1}{N} \\sum x_i \\quad \\text{and} \\quad \\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{N}}\n",
    "    $$\n",
    "- **Heteroscedastic**: Uncertainties vary for each data point $\\sigma_i$. Then use a **weighted mean**:\n",
    "    $$\n",
    "    \\bar{x} = \\frac{\\sum x_i / \\sigma_i^2}{\\sum 1 / \\sigma_i^2}\n",
    "    $$\n",
    "    $$\n",
    "    \\sigma_{\\bar{x}}^2 = \\frac{1}{\\sum 1/\\sigma_i^2}\n",
    "    $$\n",
    "This two formula are extracted from the derivative of the log-Likelihood = 0 , that' because we are searching for a maximum.\n",
    "\n",
    "Our Maximum Likelihood Estimator (MLE) is not perfect — every estimate has an associated **uncertainty** due to the finite sample size.\n",
    "\n",
    "Under general conditions, the MLE becomes **asymptotically normal**, meaning that for large $N$, the likelihood function can be approximated by a **Gaussian** centered at the true parameter value $\\theta_0$.\n",
    "\n",
    "To quantify the uncertainty, we expand the **log-likelihood** around its maximum using a second-order **Taylor expansion**:\n",
    "\n",
    "$$\n",
    "\\log \\mathcal{L}(\\theta) \\approx \\log \\mathcal{L}(\\hat{\\theta}) - \\frac{1}{2} (\\theta - \\hat{\\theta})^2 F(\\hat{\\theta})\n",
    "$$\n",
    "\n",
    "Here, $F(\\hat{\\theta})$ is the **Fisher Information Matrix**, defined as the negative second derivative (Hessian) of the log-likelihood:\n",
    "\n",
    "$$\n",
    "F(\\theta) = - \\frac{\\partial^2}{\\partial \\theta_i \\partial \\theta_j} \\log \\mathcal{L}(\\theta)\n",
    "$$\n",
    "\n",
    "The **covariance matrix** of the estimator $\\hat{\\theta}$ is then given by the **inverse** of the Fisher matrix:\n",
    "\n",
    "$$\n",
    "\\text{Cov}(\\hat{\\theta}) = F^{-1}(\\hat{\\theta})\n",
    "$$\n",
    "\n",
    "For a **single parameter** $\\theta$, this simplifies to:\n",
    "\n",
    "$$\n",
    "\\sigma_{\\hat{\\theta}} = \\sqrt{\\frac{1}{F(\\hat{\\theta})}}\n",
    "$$\n",
    "\n",
    "This implies that asymptotically, the MLE is **normally distributed**:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} \\sim \\mathcal{N} \\left( \\theta_0, F^{-1}(\\theta_0) \\right)\n",
    "$$\n",
    "---\n",
    "\n",
    "### **Non-Gaussian Likelihoods**\n",
    "\n",
    "- When the data doesn’t follow a Gaussian distribution, use the appropriate **likelihood model**, such as : **Poisson**, **Binomial**, **Exponential**, **Log-normal**, etc.\n",
    "- The MLE approach still applies: choose the model, write the likelihood, and maximize it numerically.\n",
    "- In most of the cases, you will find the same result as in the gaussian one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa14af5",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 6** - Frequentist Inference II </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608a02e5",
   "metadata": {},
   "source": [
    "- Fit  \n",
    "- Outliers (Huber loss function)  \n",
    "- Goodness of fit  \n",
    "- Reduced chi-squared  \n",
    "- Model misspecification  \n",
    "- Occam’s Razor  \n",
    "- AIC (Akaike Information Criterion)  \n",
    "- Bootstrap  \n",
    "- Jackknife"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe2ed34",
   "metadata": {},
   "source": [
    "### **Fit**\n",
    "\n",
    "- Fitting means adjusting model parameters so that the model best matches the observed data.\n",
    "- Typically done by minimizing a loss function, such as the **sum of squared residuals** or **negative log-likelihood**.\n",
    "- The goal is to find the best estimate $\\hat{\\theta}$ that explains the data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Outliers and Huber Loss Function**\n",
    "\n",
    "- **Outliers** are data points that deviate significantly from the trend of the rest of the data.\n",
    "- Standard least squares are very sensitive to outliers.\n",
    "- How do we deal with outliers? By modifying the likelihood!\n",
    "- The **Huber loss** combines the squared loss for small errors and absolute loss for large errors:\n",
    "\n",
    "$$\n",
    "L_{\\text{Huber}}(t) =\n",
    "\\begin{cases}\n",
    "\\frac{1}{2} t^2 & \\text{if } |t| \\leq c \\\\\n",
    "c |t| - \\frac{1}{2} c^2 & \\text{if } |t| > c\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- Where $t = \\left| \\frac{y - M(\\theta)}{\\sigma} \\right|$ represents the **standardized residual**, i.e. how far the observed value $y$ is from the model prediction $M(\\theta)$, in units of the known uncertainty $\\sigma$.\n",
    "- $c$ is the **tuning constant** (or confidence threshold), which determines the cutoff point where the loss switches from quadratic to linear. A common value is $c \\approx 1.345$, which gives good balance between efficiency and robustness under normal errors.\n",
    "- This approach makes the fit more **robust** to outliers: small residuals behave like in least squares, but large residuals are penalized less harshly.\n",
    "- Note that by doing this, we are effectively putting **prior information** into the analysis\n",
    "\n",
    "---\n",
    "\n",
    "### **Goodness of Fit : Reduced Chi-squared**\n",
    "\n",
    "- Measures how well the model describes the data. Remember GIGO (Garbage In Garbage Out), if the model is wrong , finding the \"best\" parameter doesn't really mean something ...\n",
    "- A good fit should show residuals randomly scattered around zero.\n",
    "\n",
    "- The **reduced chi-squared** is defined as:\n",
    "\n",
    "$$\n",
    "\\chi^2_{\\text{red}} = \\frac{1}{\\nu} \\sum_{i=1}^N \\left( \\frac{y_i - f(x_i)}{\\sigma_i} \\right)^2\n",
    "$$\n",
    "\n",
    "where $\\nu = N - k$ is the number of degrees of freedom (data points minus number of parameters).\n",
    "\n",
    "- Interpretation:\n",
    "  - $\\chi^2_{\\text{red}} \\approx 1$: good fit\n",
    "  - $\\chi^2_{\\text{red}} \\gg 1$: underfitting or underestimated errors\n",
    "  - $\\chi^2_{\\text{red}} \\ll 1$: overfitting or overestimated errors\n",
    "- If the model is **wrong** (misspecified), goodness-of-fit measures can be misleading.\n",
    "\n",
    "---\n",
    "\n",
    "### **Model Comparison, Occam’s Razor , AIC and BIC**\n",
    "- You can't do $\\chi^2_{\\text{red}}$ with Huber function, because it's not gaussian!\n",
    "- When comparing two models with the **same number of parameters**, we can simply compare their **maximum log-likelihood** values:\n",
    "- Larger log-likelihood ⇒ better fit\n",
    "\n",
    "The **Huber loss** clearly performs better (less negative log-likelihood), meaning it fits the data more effectively, especially in the presence of outliers.\n",
    "\n",
    "\n",
    "When models have **different numbers of parameters**, simply comparing likelihoods is not fair: more complex models might fit better **just by chance**. We need to penalize complexity — this is known as the **Occam penalty**.\n",
    "\n",
    "\n",
    "A simple method to compare models with different complexity is the **AIC** (Akaike Information Criterion):\n",
    "  \n",
    "- Lower AIC is better for the explaination of the dataset\n",
    "- It's composed by lot of term, the first one it's the $\\chi^2$, the second and third penalize model complexity\n",
    "- If models fit the data equally well, AIC prefers the one with fewer parameters.\n",
    "\n",
    "\n",
    "\n",
    "The **BIC** (Bayesian Information Criterion) is another way to compare models, especially when they have different numbers of parameters.\n",
    "It’s similar to AIC, but it **penalizes complex models more strongly**, especially when the dataset is large.\n",
    "\n",
    "\n",
    "- Lower **BIC** means a better model.\n",
    "- BIC prefers **simpler models**, especially when $n$ is large.\n",
    "- It’s often used in **Bayesian statistics**, but doesn’t need a full Bayesian analysis, often use in frequentist analysis too.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Bootstrap**\n",
    "\n",
    "- A **resampling method** to estimate uncertainties and confidence intervals.\n",
    "- Keep attention : it create information out of nothing!\n",
    "- Steps:\n",
    "  1. Resample data (with replacement) to create many datasets. The probability of getting the original dataset it's extreamly low ($N! / N^N$)\n",
    "  2. Fit the model to each resampled dataset.\n",
    "  3. Analyze the distribution of the fitted parameters.\n",
    "- Useful when analytical uncertainty is hard to compute or it's too big (such as when we have few point for a gaussian distribution).\n",
    "\n",
    "---\n",
    "\n",
    "###  **Jackknife Method** \n",
    "\n",
    "The **Jackknife** is a method to estimate the **uncertainty** (standard error) and **bias** of a statistic — like the **mean** or **standard deviation** — using your data.\n",
    "\n",
    "Suppose you have a dataset of $N$ values.\n",
    "\n",
    "1. Leave out **one** data point at a time → you get $N$ new datasets.\n",
    "2. Compute your statistic (e.g. mean, std) on each of these.\n",
    "3. From the $N$ results, estimate:\n",
    "   - A **better (bias-corrected)** value of the statistic\n",
    "   - The **uncertainty** on that value\n",
    "\n",
    "\n",
    "Jackknife works **well** when the statistic is:\n",
    "- The **mean**\n",
    "- The **standard deviation**\n",
    "\n",
    "It works **poorly** for:\n",
    "- The **median**\n",
    "- **Quantiles** (e.g. the 25th percentile)\n",
    "\n",
    "These are called **rank-based statistics**, and removing one point at a time doesn’t change them much — so the jackknife underestimates the uncertainty.\n",
    "\n",
    "\n",
    "####  **Jackknife vs Bootstrap**\n",
    "\n",
    "|                | Jackknife                | Bootstrap                |\n",
    "|----------------|--------------------------|--------------------------|\n",
    "| Type           | Leaves out one point     | Resamples with replacement |\n",
    "| Fast?          | ✅ Yes                   | ❌ Slower               |\n",
    "| Repeatable?    | ✅ Always same result     | ❌ Changes each time    |\n",
    "| Works for all stats? | ❌ Not for medians       | ✅ Yes                 |\n",
    "| Confidence intervals | ❌ Approximate         | ✅ Full distribution     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a611a0",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 7** - Frequentist Inference III </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f4b80",
   "metadata": {},
   "source": [
    "- Hypothesis testing (p-value)  \n",
    "- Null hypothesis  \n",
    "- Type I and Type II errors  \n",
    "- KS test (Kolmogorov–Smirnov)  \n",
    "- Histograms  \n",
    "- Number of bins (Scott’s & Freedman–Diaconis rules)  \n",
    "- Rug plot  \n",
    "- Kernel Density Estimation (Gaussian and Epanechnikov)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b0c6fe",
   "metadata": {},
   "source": [
    "### **Hypothesis Testing and p-value**\n",
    "\n",
    "Hypothesis testing is a fundamental procedure in statistics used to decide whether there is enough evidence in a sample of data to infer that a certain condition holds for the entire population.\n",
    "\n",
    "- **Null Hypothesis ($H_0$):** This is the starting assumption or the default claim about the population. It usually represents the idea that there is **no effect**, **no difference**, or **no relationship** between variables. For example, $H_0$ might state that the mean of a population is equal to a specific value.\n",
    "\n",
    "- **Alternative Hypothesis ($H_1$):** This is the hypothesis you want to test or provide evidence for. It represents a change, effect, or difference from what the null hypothesis states. \n",
    "\n",
    "- **Test Statistic:** To test the hypotheses, a test statistic is computed from the sample data. This statistic measures how far the observed data are from what would be expected if $H_0$ were true. Different tests have different statistics (e.g., t-test, z-test, chi-square test).\n",
    "\n",
    "- **p-value:** The p-value is the probability, assuming the null hypothesis $H_0$ is true, of obtaining a test statistic at least as extreme as the one observed. In other words, it quantifies how likely your data would be if there were actually no effect.\n",
    "\n",
    "  - A **small p-value** indicates that the observed data is unlikely under $H_0$, so we have evidence to reject the null hypothesis.\n",
    "  - A **large p-value** suggests the data is consistent with $H_0$, and we do not reject it.\n",
    "\n",
    "    $$\n",
    "        p_i = \\int_{x_i}^{\\infty} h_0(x)dx = 1 - \\int_{-\\infty}^{x_i}h_0(x)dx = 1- H_0(x_i)\n",
    "    $$\n",
    "\n",
    "- **Significance Level ($\\alpha$):** This is a threshold probability set before the test (commonly 0.05 or 5%). If the p-value is less than $\\alpha$, the result is called statistically significant, and we reject the null hypothesis in favor of the alternative.\n",
    "\n",
    "#### Important notes:\n",
    "\n",
    "- **Failing to reject $H_0$ is not the same as accepting $H_0$.** It means the data do not provide strong enough evidence against $H_0$, but $H_0$ might still be false.\n",
    "- The p-value does **not** measure the probability that $H_0$ is true or false; it only measures data compatibility with $H_0$.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "Suppose you want to test if a coin is fair.  \n",
    "- $H_0$: The coin is fair (probability of heads = 0.5).  \n",
    "- $H_1$: The coin is biased (probability of heads ≠ 0.5).\n",
    "\n",
    "You flip the coin 100 times, get 60 heads, and compute a test statistic. The p-value tells you how likely it is to get 60 or more heads assuming the coin is fair. If the p-value is below your threshold (e.g., 0.05), you reject $H_0$ and conclude the coin is likely biased.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Type I and Type II Errors**\n",
    "\n",
    "- **Type I error (False Positive):** Rejecting $H_0$ when it is true. (I think that some bgk it'a a source)\n",
    "- **Type II error (False Negative):** Not rejecting $H_0$ when $H_1$ is true. (I think that a source it's bgk)\n",
    "\n",
    "- Power of the test = $1 - \\alpha$ $\\rightarrow$ (probability to correctly reject $H_0$ when $H_1$ is true).\n",
    "\n",
    "- For N sample, the number of false positive will be :\n",
    "\n",
    "$$\n",
    "  n_{spuri} \\sim N \\int_{x_c}^{\\infty} h_{bgk}(x) \\, dx\n",
    "$$\n",
    "- The number of false negative will be: \n",
    "$$\n",
    "  n_{missed} \\sim N \\int_{0}^{x_c} h_S(x) \\, dx\n",
    "$$\n",
    "\n",
    "- Define the sample contamination as $\\epsilon = \\frac{n_{spuri}}{n_{source}}$\n",
    "- And 1-$\\epsilon$ is called classification efficiency.\n",
    "\n",
    "---\n",
    "\n",
    "### **Kolmogorov–Smirnov (KS) Test**\n",
    "\n",
    "- we'd like to compare two different sample and understand if they were taken from the same distribution\n",
    "- KS is a non-parametric test to compare a sample with a reference distribution, or two samples.\n",
    "- Measures the maximum distance between the empirical CDF $\\rightarrow D = max|F_1 - F_2|$\n",
    "- Outputs a statistic $D$ and a p-value.\n",
    "- amazingly D, does not dipend on the underlying distribution we care about\n",
    "- Useful to test goodness-of-fit.\n",
    "\n",
    "---\n",
    "\n",
    "### **Histograms and Number of Bins**\n",
    "\n",
    "Choosing the number of bins affects the histogram shape. The bin's width it's a hyper-parameter that has to be tune for correctly extracting the true statistics:\n",
    "\n",
    "- **Scott’s Rule:**  \n",
    "$$\n",
    "\\text{bin width} = \\frac{3.5 \\times \\sigma}{N^{1/3}}\n",
    "$$\n",
    "That's a grat rule only if we know sigma of the distribution... often it's not usable\n",
    "\n",
    "- **Freedman-Diaconis Rule:**  \n",
    "$$\n",
    "\\text{bin width} = \\frac{2 \\times IQR}{N^{1/3}}\n",
    "$$\n",
    "where $IQR$ = interquartile range between 75% and 25% and $N$ = number of data points.\n",
    "\n",
    "- By making histogram you are losing some information depending on the width of the bin you are choosing; It's possible to define the bin height uncertainty by a simple rule: \n",
    "$$\n",
    "  \\sigma_k = \\frac{\\sqrt{n_k}}{\\Delta_b \\cdot N}\n",
    "$$\n",
    "where: N is the total number of data, $n_k$ it's the numer of count in the k-bin and $\\Delta$ is the bin width\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Rug Plot**\n",
    "\n",
    "- A simple plot showing individual data points as small vertical lines (ticks) along an axis.\n",
    "- Useful to visualize the distribution of data points on top of other plots (like histograms or density plots).\n",
    "\n",
    "---\n",
    "\n",
    "### **Kernel Density Estimation (KDE)**\n",
    "\n",
    "- The core idea it's not to usa a Dirac - delta in each point, but rather a distribution.\n",
    "- All this distribution (kernel) are summed up to produce the PDF.\n",
    "- Any distribution could be use:\n",
    "\n",
    "#### Common kernels:\n",
    "\n",
    "- **Gaussian kernel:**  \n",
    "$$\n",
    "K(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\n",
    "$$\n",
    "\n",
    "- **Epanechnikov kernel:**  \n",
    "$$\n",
    "K(x) = \\frac{3}{4} (1 - x^2) \\quad \\text{for } |x| \\leq 1, \\quad 0 \\text{ otherwise}\n",
    "$$\n",
    "parabolic with a fix support, more localized then the gaussian\n",
    "\n",
    "- **linear** decrescent weights at the distance of the referement point. less smooth then the gaussian\n",
    "- **uniform**, assign the same weight at all the point in a windows and zero outside. less utileze because it can generate less precise estimation \n",
    "\n",
    "\n",
    "KDE bandwidth controls the smoothness (similar to bin width for histograms). That's an hyper parameter that has to be tune fine before the analysis thanks to Cross Validation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8008fa4",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 8** - Bayesian Inference I </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ef596f",
   "metadata": {},
   "source": [
    "- Bayes recap  \n",
    "- Bayesian method  \n",
    "- Prior  \n",
    "- 3 Bayesian principles  \n",
    "- Credibility regions  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a805e709",
   "metadata": {},
   "source": [
    "\n",
    "### **Bayes Recap – Principles and Rules**\n",
    "\n",
    "Bayes' theorem allows us to **update our belief** about a hypothesis or a parameter after observing new data. The core formula is:\n",
    "\n",
    "$P(\\theta| D) = \\dfrac{P(D | \\theta) \\cdot P(\\theta)}{P(D)}$\n",
    "\n",
    "Where:\n",
    "- $\\theta$:  parameters values\n",
    "- $D$: observed data\n",
    "- $P(\\theta)$: **prior** – initial belief before seeing the data\n",
    "- $P(D | \\theta)$: **likelihood** – probability of observing $D$ assuming $H$ is true\n",
    "- $P(\\theta | D)$: **posterior** – updated belief after seeing the data\n",
    "- $P(D)$: normalization constant (also called **evidence**)\n",
    "\n",
    "---\n",
    "\n",
    "### **Bayesian Method** \n",
    "\n",
    "1. **Define the problem** – Choose the model and the parameter $\\theta$ to estimate.\n",
    "2. **Assign the prior** $P(\\theta)$ – Express your knowledge or assumptions about $\\theta$ before the data.\n",
    "3. **Define the likelihood** $P(D | \\theta)$ – Describe how the data is generated from $\\theta$.\n",
    "4. **Compute the posterior** $P(\\theta | D)$ – Using Bayes’ theorem.\n",
    "5. **Estimate the parameter** – Use the posterior to get a point estimate (e.g. MAP, mean, median).\n",
    "6. **Quantify uncertainty** – Through credibility intervals, variance, etc.\n",
    "\n",
    "$$\n",
    "  \\text{Posterior probability} = \\frac{\\text{Likelihood} X \\text{Prior}}{\\text{Evidence}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### **Prior Distributions** \n",
    "\n",
    "The choice of prior is a crucial part of Bayesian analysis. \n",
    "There are 2 type of prior:\n",
    "- Informative : riflect pre-existing belives\n",
    "- Uninformative : usable when you don't want to make strong hypotesis on the event\n",
    "\n",
    "When no strong prior information is available, there are three main principles to guide the choice:\n",
    "\n",
    "- **Principle of indifference**: Assign equal probabilities when there is no reason to prefer one value over another. (1/2 on a coin)\n",
    "- **Invariance principle**: The prior should remain consistent under reparameterization.\n",
    "- **Maximum entropy**: Among all distributions compatible with known constraints, choose the one with the highest entropy (least informative).\n",
    "\n",
    "If you choose the wrong prior, it's your fault, only an anormus amount of data could correct your initial belif, in this case you can say that are \"data dominated\", otherwise you are \"prior dominated\"\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Bayesian Credible Regions**\n",
    "\n",
    "- A **credible region** (e.g. 95%) contains the parameter values for which the posterior probability sums up to 95%.\n",
    "\n",
    "- Unlike frequentist intervals, credible regions express *degree of belief*:  \n",
    "  “Given the data, there is a 95% probability that the true parameter lies in this region.”\n",
    "\n",
    "---\n",
    "\n",
    "### **Credible Region vs Confidence Interval**\n",
    "\n",
    "In **Bayesian inference**, a *credible region* represents the interval within which the parameter lies with a given probability (e.g., 95%), based on the **posterior distribution**. This directly expresses our updated belief after seeing the data. In contrast, the **frequentist confidence interval** does not assign a probability to the parameter itself (which is considered fixed), but rather to the procedure: if the experiment were repeated many times, 95% of the computed intervals would contain the true parameter. Thus, the Bayesian credible region reflects belief about the parameter, while the frequentist confidence interval reflects properties of repeated sampling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d714fef0",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 9** - Bayesian Inference II </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252d661e",
   "metadata": {},
   "source": [
    "- Odds ratios  \n",
    "- Bayes factors  \n",
    "- Frequentist vs Bayesian  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c917c07",
   "metadata": {},
   "source": [
    "\n",
    "### **Odds Ratio $(\\mathcal{O})$**\n",
    "\n",
    "- The **Odds Ratio** is the ratio of the posterior probabilities of two competing models $M_1$ and $M_0$:\n",
    "\n",
    "  $$\n",
    "  \\mathcal{O}_{10} = \\frac{P(M_1 | D)}{P(M_0 | D)} = \\frac{P(D | M_1)}{P(D | M_0)} \\cdot \\frac{P(M_1)}{P(M_0)} = B_{10} \\cdot \\frac{P(M_1)}{P(M_0)}\n",
    "  $$\n",
    "\n",
    "- It combines the **Bayes Factor** and the **prior odds** to update our belief in which model is more likely after seeing the data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Bayes Factor $(\\mathcal{B})$**\n",
    "\n",
    "- The **Bayes Factor** is the ratio of marginal likelihoods (evidences) of the two models:\n",
    "\n",
    "  $$\n",
    "  B_{10} = \\frac{P(D | M_1)}{P(D | M_0)}\n",
    "  $$\n",
    "\n",
    "- It measures how well each model explains the observed data, **independent of prior model probabilities**.\n",
    "\n",
    "- Interpretation (Jeffreys scale):\n",
    "\n",
    "  | $B_{10}$ Value        | Strength of Evidence for $M_1$ |\n",
    "  |------------------------|-------------------------------|\n",
    "  | $<1$                   | Evidence against $M_1$        |\n",
    "  | $1 - 3$                | Weak                          |\n",
    "  | $3 - 10$               | Moderate                      |\n",
    "  | $10 - 100$             | Strong                        |\n",
    "  | $>100$                 | Decisive                      |\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### **Bayesian Hypothesis Testing**\n",
    "\n",
    "- In the **Bayesian approach**, hypothesis testing is based on computing the **posterior probabilities** of hypotheses given the observed data.\n",
    "\n",
    "- For two competing hypotheses, $H_0$ and $H_1$, we compute:\n",
    "\n",
    "  $$\n",
    "  P(H_0 | D) = \\frac{P(D | H_0) \\cdot P(H_0)}{P(D)}\n",
    "  \\qquad\\text{and}\\qquad\n",
    "  P(H_1 | D) = \\frac{P(D | H_1) \\cdot P(H_1)}{P(D)}\n",
    "  $$\n",
    "\n",
    "- The **Bayes factor** $B_{10}$ is :\n",
    "  $$\n",
    "  B_{10} = \\frac{P(D | H_1)}{P(D | H_0)}\n",
    "  $$\n",
    "\n",
    "- It tells us how much more likely the data is under $H_1$ than under $H_0$.\n",
    "\n",
    "- Final decision depends on both:\n",
    "  - The Bayes factor\n",
    "  - The **prior probabilities** of the hypotheses\n",
    "\n",
    "- No fixed significance threshold like 0.05 is used. Instead, we interpret **posterior odds** and **Bayes factors**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Frequentist vs Bayesian Approach**\n",
    "\n",
    "|                       | Frequentist                        | Bayesian                            |\n",
    "|-----------------------|------------------------------------|-------------------------------------|\n",
    "| Parameters            | Fixed, unknown                     | Random variables with distributions |\n",
    "| Probability           | Long-run frequency                 | Degree of belief                    |\n",
    "| Model comparison      | p-values, likelihood ratios        | Bayes factors, posterior odds       |\n",
    "| Use of prior          | Not used                           | Essential part of inference         |\n",
    "| Interpretation        | Inference based on repeated data   | Inference conditional on data       |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57e56e7",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 10** - Bayesian Inference III </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cfc965",
   "metadata": {},
   "source": [
    "- Monte Carlo  \n",
    "- Markov chains (detailed balance)  \n",
    "- MCMC (Markov Chain Monte Carlo)  \n",
    "- Metropolis–Hastings algorithm  \n",
    "- Corner plot  \n",
    "- Trace plot  \n",
    "- Burn-in  \n",
    "- Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf1f519",
   "metadata": {},
   "source": [
    "###  **Monte Carlo Methods**\n",
    "\n",
    "- **Monte Carlo methods** are computational algorithms that rely on repeated **random sampling** to estimate numerical results.\n",
    "- Widely used in physics, statistics, and Bayesian inference.\n",
    "- Particularly helpful when analytical solutions are difficult or impossible.\n",
    "- However, in high-dimensional spaces, standard Monte Carlo can become highly **inefficient**, which motivates the use of improved techniques like MCMC.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Markov Chains and Stationary Distributions**\n",
    "\n",
    "A **Markov chain** is a sequence of random variables in which the probability of transitioning to the next state depends **only** on the current state — the process is **memoryless**.\n",
    "\n",
    "In this context, a **stationary distribution** $\\pi(x)$ is a probability distribution that remains unchanged as the chain evolves:\n",
    "\n",
    "$$\n",
    "\\sum_x \\pi(x) \\cdot P(x \\to x') = \\pi(x') \\quad \\text{for every } x'\n",
    "$$\n",
    "\n",
    "This means that if the chain starts in the distribution $\\pi(x)$, it will maintain that distribution at every future step.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Detailed Balance Condition**\n",
    "\n",
    "A sufficient condition for a Markov chain to converge to a desired stationary distribution $\\pi(x)$ is the **detailed balance condition**:\n",
    "\n",
    "$$\n",
    "\\pi(x) \\cdot P(x \\to x') = \\pi(x') \\cdot P(x' \\to x)\n",
    "$$\n",
    "\n",
    "This condition ensures **reversibility** and guarantees that $\\pi(x)$ is indeed stationary.\n",
    "\n",
    "---\n",
    "\n",
    "### **Markov Chain Monte Carlo (MCMC)**\n",
    "\n",
    "- **MCMC** combines the idea of Monte Carlo sampling with Markov chains to draw samples from complex distributions.\n",
    "- The key idea is to construct a Markov chain whose stationary distribution is the **target distribution** $\\pi(x)$ (typically the posterior in Bayesian inference).\n",
    "- Even if $\\pi(x)$ is only known **up to a normalization constant**, MCMC methods can still be used to sample from it.\n",
    "\n",
    "After an initial **burn-in phase**, the samples can be treated as drawn from the true distribution.\n",
    "\n",
    "\n",
    "####  Why Use MCMC?\n",
    "\n",
    "In Bayesian inference, we are often interested in the **posterior distribution**, but computing it explicitly is hard.  \n",
    "MCMC allows us to **approximate** this distribution by generating samples from it, rather than calculating it directly.\n",
    "\n",
    "This makes MCMC a powerful and flexible tool for inference in complex models.\n",
    "\n",
    "---\n",
    "\n",
    "### **Metropolis-Hastings Algorithm**\n",
    "\n",
    "- A widely used MCMC algorithm.\n",
    "- Generates a sequence of samples that approximates $\\pi(x)$.\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. Start from an initial point $x$.\n",
    "2. Propose a new point $x'$ from a **proposal distribution** $T(x'|x)$.\n",
    "3. Compute the **acceptance probability** = $\\alpha$ = $\\frac{p(\\theta_{i+1})}{p(\\theta_i)}$\n",
    "4. Draw a uniform random number between 0 and 1 ... Accept $x'$ with probability $\\alpha$, otherwise stay at $x$.\n",
    "5. Repeat the process to create a Markov chain.\n",
    "\n",
    "---\n",
    "\n",
    "### **Burn-in and Plot**\n",
    "\n",
    "- The early steps of MCMC may not represent the target distribution well.\n",
    "- The **burn-in period** refers to the initial segment of the chain that is discarded.\n",
    "- A **trace plot** shows the sampled values over steps — used to check convergence.\n",
    "- A **corner plot** (also called pair plot) is used to visualize multidimensional posterior distributions, it Shows histograms of each parameter.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Correlation Length**\n",
    "\n",
    "In an MCMC simulation, **correlation length** (also called **autocorrelation time**) refers to how many steps it takes for samples in the chain to become approximately **independent** from each other.\n",
    "\n",
    "- If samples are highly correlated, the chain is moving slowly through the space, and many steps are needed to obtain independent samples.\n",
    "- The **effective number of samples** is smaller than the total number of steps taken.\n",
    "\n",
    "This is why understanding and **reducing correlation** is important to improve sampling efficiency.\n",
    "\n",
    "We often define the correlation length $\\tau$ such that:\n",
    "\n",
    "$$\n",
    "\\text{Effective samples} \\approx \\frac{N_\\text{total}}{\\tau}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step Size Tuning**\n",
    "\n",
    "The **step size** controls how far the chain jumps between states. Choosing it well is crucial:\n",
    "\n",
    "- If the step is **too small**: the chain moves slowly, samples are highly correlated → inefficient exploration.\n",
    "- If the step is **too large**: the chain proposes states far from the current one, and many of them get **rejected** → again, inefficient.\n",
    "\n",
    "the **Goal** is balance **acceptance rate** and **decorrelation**.\n",
    "\n",
    "Typical strategy:\n",
    "- Tune the step size to achieve a **moderate acceptance rate** (e.g. ~20–40% for Metropolis-Hastings).\n",
    "- Monitor the **autocorrelation** or use **diagnostic plots** (e.g. trace plot) to check if the chain is mixing well.\n",
    "\n",
    "There is no universal best step size: it depends on the shape of the target distribution and the algorithm used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59df8be",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 11** - Bayesian Inference IV </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed5d0e0",
   "metadata": {},
   "source": [
    "- Thinning  \n",
    "- Adaptive Metropolis  \n",
    "- Single Component Adaptive Metropolis  \n",
    "- Hamiltonian Monte Carlo  \n",
    "- Emcee  \n",
    "- Gibbs sampling  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc1488",
   "metadata": {},
   "source": [
    "### **Thinning**\n",
    "\n",
    "**Definition**: Thinning is the practice of keeping only every *k*-th sample from an MCMC chain (e.g., every 10th sample).\n",
    "\n",
    "- The goal of MCMC is to approximate the **posterior distribution** by generating samples from it.\n",
    "- However, successive samples from the MCMC are usually **autocorrelated**.\n",
    "- Thinning attempts to reduce this autocorrelation by discarding intermediate samples.\n",
    "- **Note**: Modern practice often recommends storing all samples and addressing autocorrelation during post-processing, since thinning can discard useful information and reduce effective sample size unnecessarily.\n",
    "\n",
    "---\n",
    "\n",
    "### **Adaptive Metropolis**\n",
    "\n",
    "**Definition**: An MCMC method that adapts the proposal distribution based on the history of the chain.\n",
    "\n",
    "- In the **Metropolis-Hastings** algorithm, choosing a good proposal distribution is crucial.\n",
    "- Adaptive Metropolis (AM) automatically tunes the **covariance matrix** of the proposal distribution as the chain progresses.\n",
    "- This allows better exploration of the posterior, especially in high-dimensional or correlated parameter spaces.\n",
    "- This method doesn't use only the last point, but it use the entire chain, our chain is no longer markovian.\n",
    "- To fix this, we often let the algorithm \"learn\" during an initial phase (called the tuning stage), where it adapts the proposal. After that, we stop adapting and keep the proposal fixed — from that moment on, the chain becomes Markovian again and gives valid Bayesian results.\n",
    "---\n",
    "\n",
    "### **Single Component Adaptive Metropolis (SCAM)**\n",
    "\n",
    "**Definition**: A variant of Adaptive Metropolis where only one parameter (component) is updated at a time.\n",
    "\n",
    "- Standard MCMC or AM methods like Metropolis-Hastings suffer of low rate in high-dimensional spaces.\n",
    "- SCAM is especially useful when parameters have **different scales or conditional dependencies**.\n",
    "- At each iteration, only one dimension of the parameter vector is updated, often using an adaptive univariate proposal.\n",
    "- This can be more efficient than updating all parameters jointly, especially in the presence of strong correlations.\n",
    "- The adaptation improves sampling efficiency over time.\n",
    "\n",
    "---\n",
    "\n",
    "### **Other method**\n",
    "\n",
    "**Hamilton Monte Carlo**: An MCMC algorithm that uses concepts from physics (Hamiltonian dynamics) to make informed proposals in parameter space, improving efficiency in exploring complex posterior distributions.\n",
    "**Differential Evolution** : A population-based optimization algorithm that can be adapted for MCMC by evolving a set of candidate solutions using differences between randomly selected members of the population to guide proposals.\n",
    "\n",
    "---\n",
    "\n",
    "### **`emcee`**\n",
    "\n",
    "- It's a full python package.\n",
    "- Emcee is designed to efficiently sample from **complex, anisotropic posterior distributions**.\n",
    "- It uses multiple parallel \"walkers\" that share information and adapt proposals to the geometry of the target distribution.\n",
    "- The process need a starting guess, we don't need to be too precise, the chain will eventualy converge to the true value\n",
    "- Need also the number of step for the chain, the burn-in region \n",
    "- has some specific method to discard the auto correlation lenght\n",
    "\n",
    "---\n",
    "\n",
    "### **Gibbs Sampling**\n",
    "A complete different method, it avoid acceptance rate, everything it's accepted\n",
    "1.  we initialize the sampler at some point in parameter space\n",
    "2. fix all the parameters except the first one\n",
    "3. Draw a random value from the conditional posterior probability distribution of this first parameter given the fixed values of all other parameters\n",
    "4. repeat the last procedur for all the parameter\n",
    "5. repeat everything for many Gibbs stepps\n",
    "\n",
    "- That's an incredible fast process\n",
    "- has an extremly high acceptance rate\n",
    "- very small burn-in phase\n",
    "- but, you need to know the conditional probability distribution for each parameter\n",
    "\n",
    "---\n",
    "\n",
    "### **Conjugate Prior**\n",
    "\n",
    "**Definition**:  \n",
    "In Bayesian statistics, a **conjugate prior** is a prior distribution that, when combined with a particular **likelihood function**, results in a **posterior distribution** that is in the same family as the prior.\n",
    "\n",
    "- It simplifies calculations.\n",
    "- The posterior has a known and tractable form.\n",
    "- Useful for analytical solutions and understanding posterior updates.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8444528",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 12** - Bayesian Inference V </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fa6731",
   "metadata": {},
   "source": [
    "- Savage–Dickey ratio  \n",
    "- Nested Sampling – Dynesty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba39c60a",
   "metadata": {},
   "source": [
    "### **Savage–Dickey Density Ratio**\n",
    "\n",
    "It's a shortcut to compare two models when one is a **special case** of the other.\n",
    "\n",
    "Let’s say:\n",
    "\n",
    "- $M_1$: the **simple model**, where a parameter $A = 0$ (e.g., \"no signal\")\n",
    "- $M_2$: the **full model**, where $A$ can be anything (e.g., \"signal allowed\")\n",
    "\n",
    "Then, instead of computing evidence for both models, we use this trick:\n",
    "\n",
    "$$\n",
    "\\mathcal{B} = \\frac{p(A = 0)}{p(A = 0 \\mid \\text{data})}\n",
    "$$\n",
    "\n",
    "This is the **Bayes factor** between $M_2$ and $M_1$.\n",
    "\n",
    "#### What Does It Mean?\n",
    "\n",
    "- $p(A = 0)$ is how much we believed in $A = 0$ **before seeing the data**.\n",
    "- $p(A = 0 \\mid \\text{data})$ is how much we believe in $A = 0$ **after seeing the data**.\n",
    "\n",
    "If the data makes $A = 0$ **less likely**, then $M_1$ is disfavored.\n",
    "\n",
    "#### When Can We Use It?\n",
    "\n",
    "- $M_1$ must be a **special case** of $M_2$.\n",
    "- The prior must be **separable** (e.g., flat for $A$).\n",
    "- We must be able to **sample the posterior**.\n",
    "\n",
    "#### How Do We Use It?\n",
    "\n",
    "1. Run MCMC on the full model $M_2$.\n",
    "2. From the samples, estimate $p(A = 0 \\mid \\text{data})$.\n",
    "   - For example, use a histogram or KDE on the samples of $A$.\n",
    "3. Calculate $\\mathcal{B}$ using the ratio.\n",
    "\n",
    "\n",
    "#### Why Is This Useful?\n",
    "\n",
    "- You don’t need to compute full evidences $\\mathcal{Z}_1$ and $\\mathcal{Z}_2$.\n",
    "- Fast and simple, especially when comparing null hypotheses.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Nested Sampling**\n",
    "\n",
    "Nested Sampling is a method to **compute the evidence** $\\mathcal{Z}$ in Bayesian inference:\n",
    "\n",
    "$$\n",
    "\\mathcal{Z} = \\int \\mathcal{L}(\\theta) \\, \\pi(\\theta) \\, d\\theta\n",
    "$$\n",
    "\n",
    "This is crucial for **comparing models**, since:\n",
    "\n",
    "$$\n",
    "\\text{Bayes Factor} = \\frac{\\mathcal{Z}_2}{\\mathcal{Z}_1}\n",
    "$$\n",
    "\n",
    "But computing $\\mathcal{Z}$ is hard — especially in high dimensions. That’s where Nested Sampling comes in.\n",
    "\n",
    "#### Main Idea\n",
    "\n",
    "Nested Sampling transforms the evidence integral into a **1D integral** over a new variable:\n",
    "\n",
    "- Define $X(\\lambda)$ = prior volume **above** a likelihood threshold $\\lambda$:\n",
    "\n",
    "$$\n",
    "X(\\lambda) = \\int_{\\mathcal{L}(\\theta) > \\lambda} \\pi(\\theta) \\, d\\theta\n",
    "$$\n",
    "\n",
    "- Then rewrite the evidence as:\n",
    "\n",
    "$$\n",
    "\\mathcal{Z} = \\int_0^1 \\mathcal{L}(X) \\, dX\n",
    "$$\n",
    "\n",
    "So we go from integrating over parameters $\\theta$ to integrating over a **monotonically decreasing likelihood**.\n",
    "\n",
    "\n",
    "#### How It Works\n",
    "\n",
    "1. Start with $N$ random points from the **prior**.\n",
    "2. Find the one with the **lowest likelihood**, call it $L_{\\text{min}}$.\n",
    "3. Remove it, and **replace** it with a new point sampled from the prior **subject to** $\\mathcal{L} > L_{\\text{min}}$.\n",
    "4. Keep track of the shrinking prior volume and the associated likelihoods.\n",
    "5. Approximate the 1D integral $\\mathcal{Z}$ using the sequence of $(X_i, \\mathcal{L}_i)$ points.\n",
    "\n",
    "In Python, the `dynesty` library does this automatically:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd42ce45",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 13** - Data Mining & Machine Learning </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37232c4",
   "metadata": {},
   "source": [
    "- cos'è il machine learning e scopo principale\n",
    "- features / sample / classes / istanze\n",
    "- sci-kit cos'è e come vuole i dati\n",
    "- seguenti metodi di sci-kit ( model.fit, model.predict , model.predict_proba, model.score ,model.trasform)\n",
    "- sci - kit estimator object \n",
    "- supervisionato (classificazione e regressione) esempio netflix\n",
    "- KNN velocemente\n",
    "- non supervisionato, cosa cambia da prima (clustering, dimensionality reduction), spiegazione semplice e veloce di ciascuno\n",
    "- PCA velocemente\n",
    "- isomap \n",
    "- clustering k-means velocemente\n",
    "- model validation ( confusion matrix,  training set / test set , )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc59d82b",
   "metadata": {},
   "source": [
    "### **What is Machine Learning and Its Main Purpose**\n",
    "\n",
    "Machine Learning (ML) is a branch of artificial intelligence where computers learn patterns from data to make decisions or predictions without being explicitly programmed. The main goal is to build models that generalize well on new, unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Terms**\n",
    "\n",
    "- **Features:** The input variables or attributes used to describe each data point (e.g., height, weight).  \n",
    "- **Sample / Instance:** A single data point or observation with its features (e.g., one person's measurements).  \n",
    "- **Classes:** Categories or labels that data points belong to in classification tasks (e.g., cat, dog).  \n",
    "- **Target:** The output or label we want to predict.\n",
    "\n",
    "---\n",
    "\n",
    "### **`Scikit-learn`** \n",
    "\n",
    "Scikit-learn is a popular Python library for machine learning. It provides easy-to-use tools for data preprocessing, modeling, and evaluation.\n",
    "\n",
    "- **Data format:**  \n",
    "  - Input features: a 2D array/matrix of shape $(n\\_samples, n\\_features)$.  Always in this form, it's very picky.\n",
    "  - if your x is just 1D, you have to reshape it in ND by using `np.newaxis()`\n",
    "  - Target labels: A 1D array of length $n\\_samples$.\n",
    "\n",
    "---\n",
    "\n",
    "### **Common Scikit-learn Methods**\n",
    "\n",
    "An **estimator** in scikit-learn is any object implementing at least the methods `.fit()` and `.predict()` or `.transform()`. \n",
    "Usually call model.\n",
    "\n",
    "- **`model.fit(X, y)`:** Trains the model on data $X$ with labels $y$.  \n",
    "- **`model.predict(X)`:** Predicts labels for new data $X$.  \n",
    "- **`model.predict_proba(X)`:** Gives the probability estimates for classification classes (if available).  \n",
    "- **`model.score(X, y)`:** Returns the accuracy on data $X$ compared to true labels $y$.  \n",
    "- **`model.transform(X)`:** Applies a transformation to data $X$ (used in dimensionality reduction, feature extraction).\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### **Supervised Learning**\n",
    "\n",
    "In supervised learning, the model learns from labeled data:\n",
    "\n",
    "- **Classification:** Predicting discrete labels. We will use the propriety of a dataset to predict unlabeled data.\n",
    "- **Regression:** Predicting continuous values.\n",
    "\n",
    "---\n",
    "\n",
    "### **Unsupervised Learning**\n",
    "\n",
    "Unsupervised learning deals with unlabeled data:\n",
    "\n",
    "- **Clustering:** Grouping similar data points .  \n",
    "- **Dimensionality Reduction:** Reducing data features while preserving structure , usefull in data visualization.\n",
    "- **Density Estimation** can determine the distribution of the data within the parameter space.\n",
    "\n",
    "The main difference is that no label is provided; the goal is to find hidden patterns or structure.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### **Model Validation**\n",
    "Determine how well your model will generalize from the training dataset to future unlabeled data.\n",
    "\n",
    "- **Confusion Matrix:** A matrix showing true vs. predicted classes to evaluate classification accuracy and errors.  The element on the diagnal are the one correctly identified, the off-diagonal are confunded.\n",
    "- **Training Set:** Data used to train the model.  \n",
    "- **Test Set:** Separate data used to evaluate model performance on unseen (but labeled) data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626dbe69",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 14** - Clustering </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbcc0cd",
   "metadata": {},
   "source": [
    "- whats are hyperparameter and make example\n",
    "- cross validation hyper parameter tuning\n",
    "- training  / validation / test \n",
    "- K - fold cross validation\n",
    "- mix con mcmc se massimo si trova tra due punti\n",
    "- clustering, non sappiamo come faccia , ma funziona\n",
    "- mean shift clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33b66ea",
   "metadata": {},
   "source": [
    "### **Hyperparameters**\n",
    "\n",
    "Hyperparameters are parameters that are **not learned from the data**, but set **before** the learning process begins. They control the learning process and model structure.\n",
    "They can easily fool us into thinking something wrong about the data.\n",
    "\n",
    "### Examples:\n",
    "- Number of clusters in K-means ($K$)\n",
    "- number of bins in a histogramm\n",
    "- Depth of a decision tree\n",
    "- Bandwidth in Kernel Density Estimation (KDE)\n",
    "\n",
    "These are typically chosen via **validation** methods like **cross-validation** (see below).\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### **Training / Validation / Test Sets**\n",
    "\n",
    "We can think of divide the datasei into:\n",
    "\n",
    "1. **Training set**: Used to **fit** the model.\n",
    "2. **Validation set**: Used to **tune hyperparameters** and select the best model version.\n",
    "3. **Test set**: Used only **at the end** to report the final unbiased performance of the selected model.\n",
    "\n",
    "But we know that less data is bad for ML, and also make the result dipendent on what is inside each set (think at outliars, if they fall into test gave a different risult...)\n",
    "We can solve this problem thanks to Cross Validation (CV)\n",
    "\n",
    "---\n",
    "\n",
    "### **K-Fold Cross Validation**\n",
    "\n",
    "Cross-validation is a technique to **evaluate the generalization ability** of a model by partitioning the data into multiple subsets.\n",
    "\n",
    "### Why it matters:\n",
    "- Helps prevent **overfitting** and **underfitting**\n",
    "- Makes full use of data (especially important with small datasets)\n",
    "- Gives a better estimate of model performance\n",
    "\n",
    "K-Fold is a smarter form of cross-validation:\n",
    "\n",
    "1. Split the Training data into $K$ equal parts (folds).\n",
    "2. For each fold:\n",
    "   - Use $K-1$ folds for training\n",
    "   - Use the remaining fold for validation\n",
    "3. Repeat $K$ times so every point gets to be in the validation set once.\n",
    "4. Extract the best parameter from the $K$ validation.\n",
    "5. Use the Test data to evaluate the model.\n",
    "\n",
    "We can take it to extreme by taking K = N = number of data, this is called \"Leave one  out\" Cross Validation, This drammatically increase the computational cost, but reduce gratly the variance.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Clustering**\n",
    "\n",
    "Clustering is **unsupervised learning**: grouping similar data points without knowing the labels.  \n",
    "It aims to discover structure in data by finding clusters (dense regions) of similar observations.\n",
    "\n",
    "---\n",
    "\n",
    "### **K-Means Clustering**\n",
    "\n",
    "**K-Means** is a simple and popular **centroid-based** clustering algorithm.\n",
    "\n",
    "#### How it works:\n",
    "1. Choose the number of clusters $k$ (a hyperparameter).\n",
    "2. Initialize $k$ **centroids** (usually randomly).\n",
    "3. Assign each data point to the **nearest centroid**.\n",
    "4. Update centroids as the **mean of points assigned** to each cluster.\n",
    "5. Repeat steps 3–4 until convergence (no significant change in centroids or assignments).\n",
    "\n",
    "**Objective:** Minimize the **within-cluster sum of squares** (WCSS):\n",
    "\n",
    "$$\n",
    "\\text{WCSS} = \\sum_{i=1}^{k} \\sum_{x \\in C_i} \\|x - \\mu_i\\|^2\n",
    "$$\n",
    "\n",
    "where $C_i$ is the set of points in cluster $i$ and $\\mu_i$ is the centroid of $C_i$. $K$ is the number of cluster. You are minimizing the distance between points and centroid for each cluster\n",
    "\n",
    "#### Strengths:\n",
    "- Efficient and scalable\n",
    "- Easy to implement\n",
    "\n",
    "#### Weaknesses:\n",
    "- Requires choosing $k$\n",
    "- Assumes spherical, equally sized clusters\n",
    "- Sensitive to initialization\n",
    "- Sensitive to outliers\n",
    "\n",
    "---\n",
    "\n",
    "### **Mean Shift Clustering**\n",
    "\n",
    "**Mean Shift** is a **non-parametric**, **density-based**, **centroid-shifting** clustering algorithm.\n",
    "\n",
    "#### How it works (Density Gradient Ascent):\n",
    "1. Define a **window (kernel)** around each data point — typically a Gaussian with bandwidth $h$.\n",
    "2. Compute the **mean of data points** within the window.\n",
    "3. Move (shift) the window center toward the **mean**.\n",
    "4. Repeat steps 2–3 until convergence (i.e., the center stops moving).\n",
    "5. Merge points converging to the same center into a **single cluster**.\n",
    "\n",
    "\n",
    "It performs **gradient ascent** on a kernel density estimate (KDE). The mode (maximum) of the KDE becomes the cluster center.\n",
    "\n",
    "\n",
    "#### Strengths:\n",
    "- **Does not require predefining the number of clusters**\n",
    "- Can identify clusters of **arbitrary shape**\n",
    "- **Robust** to outliers\n",
    "- Works well when clusters correspond to **modes in the density**\n",
    "\n",
    "#### Weaknesses:\n",
    "- Computationally expensive (especially on large datasets)\n",
    "- **Bandwidth selection** is critical — too large merges clusters, too small splits them\n",
    "- Does not scale well in high dimensions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e702ced8",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 15** - Dimensional Reduction I </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d3afd",
   "metadata": {},
   "source": [
    "- Curse of Dimensionality\n",
    "- PCA (apply a trasform to the data such that the new axes are aligned with the maximal variance of the data, ortogonalization in more dimension, fewer then the original dimension: some are discard, at the end of the game it's a diagonalization)\n",
    "- data preparization for PCA: subtract the mean, divide by the variance , normalize eachsample\n",
    "- in spectral imaging from galaxxy, every peak grow on a background , that's not noise, it's physisc, but i can remove it thanks to PCA\n",
    "- scree plot, first 2 comoponent exlain 96% of the variance in our example\n",
    "- interpreting PCA result\n",
    "- PCA it's linear, it struggle a lot with non linear component\n",
    "- Recostruction of dark area with PCA\n",
    "- overview of non-negative  matrix factorization\n",
    "- overvie (just know it exist) of ICA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea595a6",
   "metadata": {},
   "source": [
    "### **Curse of Dimensionality**\n",
    "\n",
    "As the number of features (dimensions) increases:\n",
    "- The volume of space increases exponentially.\n",
    "- Data becomes **sparse**, even if you have a lot of it.\n",
    "- Models struggle to generalize well.\n",
    "- Distance metrics (like Euclidean distance) lose meaning — all points start to look equally distant.\n",
    "\n",
    "Example: If each feature has a 50% chance of matching, the probability that all $n$ match is $0.5^n$. Even with just 4 features, that’s only 6.25%!\n",
    "\n",
    "---\n",
    "### **PCA (Principal Component Analysis)**\n",
    "\n",
    "PCA is a technique to **reduce dimensionality** by projecting data to a new space:\n",
    "- New axes are the directions of **maximum variance**.\n",
    "- These axes (principal components) are **orthogonal**.\n",
    "- Redundant dimensions are **discarded**.\n",
    "- The process is equivalent to **diagonalizing the covariance matrix**.\n",
    "\n",
    "#### Steps:\n",
    "1. **Center the data**: Subtract the mean.\n",
    "2. **Scale the data**: Divide by the standard deviation.\n",
    "3. **Normalize samples** (optional, done for spectral images).\n",
    "4. Compute the **covariance matrix**.\n",
    "5. Compute **eigenvectors/eigenvalues**.\n",
    "6. Sort eigenvectors by decreasing eigenvalue → these are the principal components. (eingvalues reflect the variance)\n",
    "\n",
    "One you have the eigenvectors $e_j(k)$, you can recostruct a true data $x_i(k)$ in the eigenvecture basis as: \n",
    "\n",
    "$$\n",
    "    x_i(k) = \\mu(k) + \\sum_j \\theta_{ij}e_j(k)\n",
    "$$\n",
    "\n",
    "#### PCA Limitations\n",
    "\n",
    "- **Linear**: PCA can’t handle **non-linear structures** in data.\n",
    "- Struggles with **curved manifolds** (e.g., spirals).\n",
    "- We would need all the component for the 100% exlaination\n",
    "- how many component should i keep? Cross validation is the answer ...\n",
    "\n",
    "let's look at the video for a better comprensation of how it work\n",
    "\n",
    "---\n",
    "\n",
    "### **Scree Plot & Explained Variance**\n",
    "\n",
    "A **scree plot** shows eigenvalues (variance explained) by each principal component.\n",
    "\n",
    "In our exaple the first 2 components explain 96% of the variance:\n",
    "- So you can reduce your data to 2D while keeping most information.\n",
    "- Useful for **visualization** and **noise reduction**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Dark Area Reconstruction with PCA**\n",
    "\n",
    "You can use PCA to reconstruct **missing or corrupted data** (e.g., missing regions in astronomical images):\n",
    "- Fit PCA on complete data.\n",
    "- Project corrupted sample into the PC space.\n",
    "- Reconstruct using the leading PCs → fill in missing values based on structure learned from the rest.\n",
    "\n",
    "---\n",
    "\n",
    "### **Overview: Non-Negative Matrix Factorization (NMF)**\n",
    "\n",
    "**NMF** is a technique that factorizes a matrix $X$ into the product of two matrices:\n",
    "\n",
    "$$\n",
    "X \\approx WH\n",
    "$$\n",
    "\n",
    "with the important constraint that **all elements of** $W$ and $H$ are **non-negative** (i.e., no negative numbers allowed).\n",
    "\n",
    "This makes the results easier to interpret in many real-world cases, especially when the data naturally can't be negative (like pixel intensities or word counts).\n",
    "\n",
    "**Applications:**\n",
    "- Discovering topics in a collection of documents\n",
    "- Breaking down images into basic components\n",
    "- Analyzing spectral data in astronomy or chemistry\n",
    "\n",
    "Compared to **PCA**, which can use negative values, **NMF tends to produce more interpretable results**, often representing **distinct parts** of the input (like separate topics or objects).\n",
    "\n",
    "---\n",
    "\n",
    "#### **Just Know It Exists: ICA (Independent Component Analysis)**\n",
    "\n",
    "**ICA** is another method for decomposing data, but instead of focusing on variance (like PCA), it looks for **independent** components.\n",
    "\n",
    "That means it tries to separate a complex signal into **underlying sources** that are as statistically **independent** from each other as possible.\n",
    "\n",
    "**Typical use cases:**\n",
    "- **Blind source separation** (e.g., separating different voices recorded by multiple microphones)\n",
    "- Analyzing EEG brain signals\n",
    "- Uncovering independent trends in financial time series\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122589a8",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 16** - Dimensional Reduction II </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb5440",
   "metadata": {},
   "source": [
    "- random forest\n",
    "- manifold learning techniques\n",
    "- Locally Linear Embedding (what is it, scheme of what is doing)\n",
    "- IsoMap (what is it, scheme of what is doing)\n",
    "- t - SNE (overview)\n",
    "- Density Estimation (recup)\n",
    "- non parametric DE ( KDE , Nearest-Neighbor Density Estimation)\n",
    "- Parametric Density Estimation (Gaussian Mixture Models) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d1156c",
   "metadata": {},
   "source": [
    "PCA, ICA and NFM are useless in handwritten dataset... they fail, let's have a look at other possible dimensionality reduction, more helpfull in this case.\n",
    "\n",
    "### **Random Forest**\n",
    "\n",
    "**Random Forest** is a machine learning method that helps make **predictions** — like: Is this email spam? What’s the price of this house?\n",
    "\n",
    "- It builds **many decision trees**.\n",
    "- Each tree gives its own answer.\n",
    "- Then it **combines the answers**:\n",
    "  - For classification (like spam/not spam): it chooses the **most common** answer (majority vote).\n",
    "  - For regression (like price): it takes the **average**.\n",
    "\n",
    "How the trees are built:\n",
    "\n",
    "- Each tree is trained on a **random sample** of the data called Bootstrap.\n",
    "- Each tree looks at only a **random set of features** when making decisions.\n",
    "\n",
    "**Random Forest = Many random trees working together to make smart predictions!**\n",
    "\n",
    "**Key Idea**: Combine many weak learners (trees) into a strong learner.\n",
    "\n",
    "---\n",
    "\n",
    "## **Manifold Learning Techniques**\n",
    "\n",
    "Manifold learning methods are **non-linear dimensionality reduction techniques** that assume data lies on a low-dimensional manifold embedded in a high-dimensional space. These techniques aim to **uncover the underlying structure** of the data.\n",
    "\n",
    "\n",
    "### **Locally Linear Embedding (LLE)**\n",
    "\n",
    "LLE is a **non-linear dimensionality reduction** algorithm that preserves local neighborhoods geometry around each point.\n",
    "\n",
    "**What is it?**\n",
    "\n",
    "- Assumes each data point and its neighbors lie on a locally linear patch of the manifold.\n",
    "- Computes weights that best reconstruct each point from its neighbors.\n",
    "- Finds low-dimensional embeddings that best preserve these local relationships.\n",
    "\n",
    "**Scheme:**\n",
    "\n",
    "1. For each point, identify $k$ nearest neighbors.\n",
    "2. Compute weights $w_{ij}$ to reconstruct point $x_i$ **from** its neighbors:  \n",
    "   $x_i \\approx \\sum_j w_{ij} x_j$ where j are the neighbour points\n",
    "3. Find low-dimensional representations $y_i$ that minimize the distance between $x_i$ and new space point $y_i$ \n",
    "\n",
    "\n",
    "### **IsoMap**\n",
    "\n",
    "IsoMap is a **global non-linear dimensionality reduction** method that preserves geodesic distances between points.\n",
    "This method assumes data lies on a smooth manifold.\n",
    "\n",
    "**Scheme:**\n",
    "\n",
    "1. Construct a neighborhood graph (e.g., $k$-nearest neighbors).\n",
    "2. Compute shortest paths (geodesic distances) between all pairs using Dijkstra .\n",
    "3. Apply classical MDS (Multi-Dimensional Scaling) to the geodesic distance matrix.\n",
    "\n",
    "IsoMap preserves the **intrinsic geometry** of the data better than PCA in non-linear settings.\n",
    "\n",
    "\n",
    "### **t-SNE** \n",
    "\n",
    "**t-SNE** is a tool that helps you **visualize data** with many features (high-dimensional) in just **2D or 3D**.\n",
    "\n",
    "What it does:\n",
    "\n",
    "- It takes complex data (with lots of numbers/features) and shows it as a simple **2D or 3D plot**.\n",
    "- Points that are **similar** in the original data end up **close together** in the plot.\n",
    "- It’s really good at showing **clusters** or groups in the data.\n",
    "\n",
    "How it works:\n",
    "\n",
    "- Figures out how similar the data points are.\n",
    "- Then tries to **keep those similarities** when showing the data in 2D or 3D.\n",
    "- Uses special math (like **probabilities** and **Student-t distribution**) to do it well.\n",
    "\n",
    "\n",
    "In short : **t-SNE = A smart way to draw complex data in 2D or 3D so you can spot patterns.**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary Table of Dimensionality Reduction Methods**\n",
    "\n",
    "| Method     | Type        | Preserves     | Suitable for Visualization | Parametric | Main Use Case                          |\n",
    "|------------|-------------|----------------|-----------------------------|------------|----------------------------------------|\n",
    "| PCA        | Linear      | Global dist    | Yes                         | Yes        | General reduction, noise filtering     |\n",
    "| NMF        | Linear      | Parts-based    | Limited                     | Yes        | Topic modeling, text data              |\n",
    "| ICA        | Linear      | Indep. sources | No                          | Yes        | Signal separation (e.g., EEG, audio)   |\n",
    "| LLE        | Non-linear  | Local linearity| Yes                         | No         | Manifold learning, visualizing clusters|\n",
    "| IsoMap     | Non-linear  | Geodetics      | Yes                         | No         | Unfolding non-linear structures        |\n",
    "| t-SNE      | Non-linear  | Probability    | Yes                         | No         | Visualization of high-dim. data        |\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Density Estimation (Recap)**\n",
    "\n",
    "Density estimation aims to model the **probability distribution** of a dataset based on observed data.\n",
    "\n",
    "Two broad classes:\n",
    "\n",
    "1. **Parametric**: Assumes a specific distribution (e.g., Gaussian).\n",
    "2. **Non-Parametric**: Makes fewer assumptions; adapts to data complexity.\n",
    "\n",
    "---\n",
    "\n",
    "### **Non-Parametric Density Estimation**\n",
    "\n",
    "**Kernel Density Estimation (KDE)**\n",
    "\n",
    "- Places a kernel (e.g., Gaussian) at each data point.\n",
    "- Estimates the density at a point $x$ \n",
    "- The bandwidth controls the smoothness of the resulting density.\n",
    "We can think of it by replacing each point with a probability cloud\n",
    "\n",
    "**Nearest-Neighbor Density Estimation**\n",
    "\n",
    "- Estimates density based on the volume $V_k$ containing the $k$ nearest neighbors of $x$.\n",
    "- Formula:  \n",
    "  $\\hat{f}(x) = \\frac{k}{n V_k}$\n",
    "\n",
    "- Adapts well to **local variations** in data density.\n",
    "\n",
    "---\n",
    "\n",
    "### **Parametric Density Estimation: Gaussian Mixture Models (GMM)**\n",
    "\n",
    "GMM assumes that the data is generated from a **mixture of several Gaussian distributions**.\n",
    "\n",
    "**Definition:**\n",
    "\n",
    "- Probability density function:  \n",
    "  $p(x) = \\sum_{k=1}^K \\pi_k \\mathcal{N}(x \\mid \\mu_k, \\Sigma_k)$  \n",
    "  where $\\pi_k$ are the mixing coefficients, and $\\mathcal{N}$ is the multivariate normal.\n",
    "\n",
    "**Estimation:**\n",
    "\n",
    "- Parameters $(\\pi_k, \\mu_k, \\Sigma_k)$ are learned using the **Expectation-Maximization (EM)** algorithm.\n",
    "\n",
    "GMMs are widely used in **clustering**, **anomaly detection**, and **density modeling**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deed4c0",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 17** - Regression I </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71913440",
   "metadata": {},
   "source": [
    "- regression \n",
    "- bayesian regression\n",
    "- linear regression ( homoschedastic , SciKit.LinearRegression())\n",
    "- polynomial regressione\n",
    "- basis regression\n",
    "- kernel regression / nadara - watson regression\n",
    "- over / under fitting - CrossValidation for the best model\n",
    "-  andamento RMS or BIC Vs degree polinomial fitting\n",
    "- learning curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c23571",
   "metadata": {},
   "source": [
    "### **Regression (What is it?)**\n",
    "\n",
    "Regression is the **supervised** process that try to find the relation between x and y.\n",
    "\n",
    "That is, for a given $x$, instead of trying to estimate the **full probability distribution function (PDF)** of $y$, we often settle for a **point estimate** — the most likely expected value.\n",
    "\n",
    "Crudely: regression = **curve fitting**: finding the best function that explains the observed data.\n",
    "\n",
    "In contrast with **unsupervised learning** (like clustering), regression **requires labeled data** — pairs of $(x_i, y_i)$.\n",
    "\n",
    "---\n",
    "\n",
    "### **Bayesian Regression**\n",
    "\n",
    "In **regular regression** (like least squares), we try to find **one best-fit line** through the data.\n",
    "\n",
    "But in **Bayesian regression**, we don’t just pick one line — we look at **many possible lines**, and figure out how likely each one is.\n",
    "\n",
    "How it works (in simple terms):\n",
    "\n",
    "- We **start with a belief** (called a **prior**) about what the model could look like.\n",
    "- Then we **update that belief** using the data we observe (this gives us the **posterior**).\n",
    "- The result is a **range of possible models**, not just one.\n",
    "\n",
    "What makes it special:\n",
    "\n",
    "- It gives **probabilistic predictions** — we get a prediction *and* how uncertain it is.\n",
    "- It’s **regularized by priors**, meaning it avoids overfitting by starting with assumptions.\n",
    "- It’s great when we want to **include uncertainty** in our results.\n",
    "\n",
    "\n",
    "When to use it:\n",
    "\n",
    "- When you care about **uncertainty** in predictions\n",
    "- When data is **limited** or **noisy**\n",
    "- When you want to **combine prior knowledge** with data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Linear Regression (Homoscedastic)**\n",
    "\n",
    "This models the response $y$ as a **linear function of inputs**:\n",
    "\n",
    "$$\n",
    "y = \\theta_1 x + \\theta_0 + \\epsilon\n",
    "$$\n",
    "\n",
    "Where $\\epsilon$ is a noise term assumed to have **constant variance** (homoscedasticity):\n",
    "\n",
    "$$\n",
    "\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "Each data point restricts the set of plausible lines in parameter space $(\\theta_0, \\theta_1)$. As more points are added, the intersection of these constraints narrows.\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "\n",
    "### **Linear Regression (Heteroscedastic)**\n",
    "\n",
    "This still models the response $y$ as a **linear function of inputs**:\n",
    "\n",
    "$$\n",
    "y = \\theta_1 x + \\theta_0 + \\epsilon\n",
    "$$\n",
    "\n",
    "But now, the **variance of the noise** is **not constant** across all data points — this is called **heteroscedasticity**:\n",
    "\n",
    "$$\n",
    "\\epsilon \\sim \\mathcal{N}(0, \\sigma^2(x))\n",
    "$$\n",
    "\n",
    "This means that:\n",
    "\n",
    "- Some data points are more \"reliable\" (lower variance).\n",
    "- Others are noisier and should influence the model **less**.\n",
    "- The model should **give different weights** to different data points when fitting.\n",
    "\n",
    "If the errors are different for each point, it is better to think of the problem in matrix notation:\n",
    "\n",
    "$$\n",
    "Y = M \\theta\n",
    "$$\n",
    "\n",
    "where $Y$ is an $N$-dimensional vector of values $y_i$,\n",
    "\n",
    "$$\n",
    "Y = \n",
    "\\begin{bmatrix}\n",
    "y_0 \\\\\n",
    "\\vdots \\\\\n",
    "y_{N-1}\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "For the straight line model, $\\theta$ is simply a two-dimensional vector of regression coefficients,\n",
    "\n",
    "$$\n",
    "\\theta =\n",
    "\\begin{bmatrix}\n",
    "\\theta_0 \\\\\n",
    "\\theta_1\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "and $M$ is called the design matrix\n",
    "\n",
    "$$\n",
    "M =\n",
    "\\begin{bmatrix}\n",
    "1 & x_0 \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "1 & x_{N-1}\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "where the constant in the first column of $M$ captures the zeropoint (i.e. the constant $y$-intercept) in the regression.\n",
    "\n",
    "\n",
    "### **Multivariative**\n",
    "\n",
    "It's simply as befor, but instead of have only 2 dimension x and y, you can add more variable, such as y = ax + bz + ck + ...\n",
    "Of course a,b,c ... are achived from the **designed matrix**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Polynomial Regression**\n",
    "\n",
    "Extends linear regression by adding polynomial terms:\n",
    "\n",
    "$$\n",
    "y = w_0 + w_1 x + w_2 x^2 + \\dots + w_d x^d + \\epsilon\n",
    "$$\n",
    "\n",
    "This is still **linear in parameters**, just not linear in $x$.\n",
    "\n",
    "- More expressive models\n",
    "- Risk of **overfitting** for large degree $d$\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(degree=5), LinearRegression())\n",
    "model.fit(X, y)\n",
    "```\n",
    "\n",
    "In this case the design matrix became:\n",
    "\n",
    "$$\n",
    "M = \\begin{pmatrix}\n",
    "1 & x_0 & x_0^2 & x_0^3 \\\\\n",
    "1 & x_1 & x_1^2 & x_1^3 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "1 & x_N & x_N^2 & x_N^3\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Basis Function Regression**\n",
    "\n",
    "We use arbitrary **basis functions** $\\phi_j(x)$:\n",
    "\n",
    "Examples:\n",
    "- Polynomial: $\\phi_j(x) = x^j$\n",
    "- Gaussian: $\\phi_j(x) = \\exp\\left(-\\frac{(x - \\mu_j)^2}{2\\sigma^2}\\right)$\n",
    "- Fourier: $\\phi_j(x) = \\cos(jx), \\sin(jx)$\n",
    "\n",
    "By choosing a suitable basis, you can fit almost any shape.\n",
    "\n",
    "---\n",
    "\n",
    "### **Kernel Regression / Nadaraya-Watson Estimator**\n",
    "\n",
    "In the case of Gaussian Basis Regression, Gaussians are evenly spaced over the range of interest. If we instead placed Gaussians at the location of every data point, we get Gaussian Kernel Regression instead. Or just Kernel Regression more generally since we don't have to have a Gaussian kernel function. It is also called Nadaraya-Watson regression.\n",
    "\n",
    "This smooths the data without fitting a fixed global model.\n",
    "\n",
    "Of course you will find the perfect banwidth by using Cross Validation\n",
    "\n",
    "#### **Kernel Regression vs Kernel Density Estimation (KDE)**\n",
    "\n",
    "| Feature                     | Kernel Regression (Nadaraya-Watson)             | Kernel Density Estimation (KDE)               |\n",
    "|----------------------------|--------------------------------------------------|------------------------------------------------|\n",
    "| 🎯 **Goal**                | Predict $y$ for a given $x$                     | Estimate the **density** of the data          |\n",
    "| 📈 **Input**               | Pairs $(x_i, y_i)$                              | Single variable $x_i$                         |\n",
    "| 📤 **Output**              | Smoothed estimate of $y$ as function of $x$     | Probability density function over $x$         |\n",
    "| 📦 **Formula**             | Weighted average of $y_i$'s                     | Weighted sum of kernels centered at $x_i$     |\n",
    "| 📍 **Kernel center**       | Centered at **each $x_i$**                     | Also centered at **each $x_i$**               |\n",
    "| 🔧 **Kernel function**     | Usually Gaussian or other symmetric functions   | Same (Gaussian, Epanechnikov, etc.)           |\n",
    "| 📌 **Bandwidth**           | Controls smoothing (chosen via cross-validation)| Controls smoothing (can use rules or CV)      |\n",
    "| 🔁 **Used for**            | Non-parametric regression                       | Density estimation / plotting distributions   |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Overfitting / Underfitting — Cross-Validation**\n",
    "\n",
    "- **Underfitting**: Model too simple → can't capture patterns\n",
    "- **Overfitting**: Model too complex → memorizes noise\n",
    "\n",
    "Use **cross-validation** to estimate model performance:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(\"Mean score:\", np.mean(scores))\n",
    "```\n",
    "\n",
    "Cross-validation-Score helps select:\n",
    "- Best model complexity (e.g., polynomial degree)\n",
    "- Regularization parameters\n",
    "\n",
    "---\n",
    "\n",
    "### **RMS or BIC vs Polynomial Degree**\n",
    "\n",
    "More regression coefficients improve the ability of the model to fit all the points (reduced bias), but at the expense of model complexity and variance. Of course we can fit a Nth-degree polynomial to N data points, but that would be foolish. We'll determine the best trade-off between bias and variance through cross-validation.\n",
    "\n",
    "When we increase the complexity of a model, the data points fit the model more and more closely. However, this process does not necessarily result in a better fit to the data. Rather, if the degree is too high, then we are overfitting the data. The model has high variance, meaning that a small change in a training point can change the model dramatically.\n",
    "\n",
    "We can evaluate this using a training set, a cross-validation set and a test set.\n",
    "\n",
    "Plotting **RMS or BIC vs polynomial degree** for both the CV set and training set can help choose the optimal degree — where adding complexity no longer improves performance.\n",
    "\n",
    "#### Root Mean Squared Error (RMS):\n",
    "\n",
    "$$\n",
    "\\text{RMS} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "\n",
    "#### Bayesian Information Criterion (BIC):\n",
    "\n",
    "$$\n",
    "\\text{BIC} = k \\ln(n) - 2 \\ln(\\hat{L})\n",
    "$$\n",
    "\n",
    "- $k$: number of parameters  \n",
    "- $n$: number of observations  \n",
    "- $\\hat{L}$: maximum likelihood  \n",
    "\n",
    "#### Interpretation of RMS and BIC\n",
    "\n",
    "For low order, both the training and CV error are high. This is sign of a high-bias model that is underfitting the data.  \n",
    "For high order, the training error becomes small (by definition), but the CV error is large. This is the sign of a high-variance model that is overfitting the data.  \n",
    "The BICs give similar results.  \n",
    "We'd like to minimize the RMS or BIC, and the minimum should be the same.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Learning Curves**\n",
    "\n",
    "Learning curves show **train vs validation error** as the dataset size increases.\n",
    "\n",
    "Key patterns:\n",
    "- **High bias**: both train and val errors are high → increase model complexity\n",
    "- **High variance**: large gap between train and val → add more data or regularize\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(model, X, y, cv=5)\n",
    "```\n",
    "\n",
    "Plot to diagnose model behavior and data sufficiency. We can see two regimes:\n",
    "\n",
    "- The training and CV errors have converged. This indicates that the model is dominated by bias. Increasing the number of training points is futile. If the error is too high, you instead need a more complex model, not more training data.\n",
    "- The training error is smaller than the CV error. This indicates that the model is dominated by variance. Increasing the number of training points may help to improve the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd232ae5",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 18** - Regression II </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d9c00c",
   "metadata": {},
   "source": [
    "- Regularization\n",
    "- ridge regression\n",
    "- LASSO regularization\n",
    "- difference and similitude ridge / LASSO \n",
    "- Locally linear Regression (LOWESS / LOESS) (overwiev)\n",
    "- Non - linear regression (overwiev)\n",
    "- Gaussian process regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cadf3e",
   "metadata": {},
   "source": [
    "### **Regularization**\n",
    "\n",
    "When we make models more complex—like using very high-degree polynomials—they can start to fit the training data *too* well. This is called **overfitting**. It means the model learns not only the true pattern but also the noise in the data. As a result, the model does great on the data it has seen but performs badly on new, unseen data.\n",
    "\n",
    "**Regularization** helps prevent overfitting by adding a penalty that discourages the model from becoming too complex. This penalty keeps the model simpler and helps it generalize better to new data by balancing two things:\n",
    "- **Bias** (how much the model assumptions simplify the real data)\n",
    "- **Variance** (how much the model changes when trained on different data samples)\n",
    "\n",
    "\n",
    "Regularization is something extra we add during fitting to avoid overfitting.\n",
    "- Fitting = learning the best parameters from data.\n",
    "- Regularization = gently forcing the model to stay simple during fitting\n",
    "---\n",
    "\n",
    "### **Ridge Regression (L2 Regularization)**\n",
    "\n",
    "Ridge regression tackles overfitting by adding a penalty on the *squared size* of the coefficients (parameters). The loss function it tries to minimize becomes:\n",
    "\n",
    "$$\n",
    "\\text{Loss}_{\\text{ridge}} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^p \\theta_j^2\n",
    "$$\n",
    "\n",
    "- The first part measures how well the model fits the data.\n",
    "- The second part (with $\\lambda$) penalizes large coefficients to prevent overly complex models. Because if the parameters are too high, you can think that the function need to change a lot among point, that's overfitting.\n",
    "- $\\lambda$ in known as regularization parameter\n",
    "\n",
    "Key points:\n",
    "- **Coefficients get smaller** but don’t become exactly zero.\n",
    "- Good when many features contribute but might be correlated.\n",
    "- Keeps all features in the model but controls their impact.\n",
    "\n",
    "---\n",
    "\n",
    "### **LASSO Regression (L1 Regularization)**\n",
    "\n",
    "LASSO adds a penalty based on the *absolute value* of the coefficients:\n",
    "\n",
    "$$\n",
    "\\text{Loss}_{\\text{lasso}} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{j=1}^p |\\theta_j|\n",
    "$$\n",
    "\n",
    "What makes LASSO special:\n",
    "- It can shrink some coefficients **exactly to zero**, effectively removing those features from the model.\n",
    "- This means LASSO does **feature selection** automatically.\n",
    "- Useful when you expect only a few important features out of many.\n",
    "\n",
    "---\n",
    "\n",
    "### **Ridge vs. LASSO: Similarities and Differences**\n",
    "\n",
    "| Feature                 | Ridge                            | LASSO                               |\n",
    "|-------------------------|---------------------------------|-----------------------------------|\n",
    "| Penalty type            | Squares of coefficients ($L_2$) | Absolute values of coefficients ($L_1$) |\n",
    "| Feature selection       | No                              | Yes (some coefficients become zero) |\n",
    "| Effect on coefficients  | Shrinks smoothly towards zero   | Produces sparse solutions (some zero exactly) |\n",
    "| Best use case           | When many features matter, even if correlated | When only a few features are really important |\n",
    "\n",
    "The difference between Ridge and LASSO is just the shape of the constraint region. For LASSO, the shape is such that some of the parameters may end up being 0, which is super beneficial.\n",
    "\n",
    "Setting $\\lambda = 0 $ is mathemathicall identical to no regularizaion. But that's not necessarily true in the scikit-learn implementation: i.e. Ridge and Lasso with lambda =0 might not give the same result of LinearRegression. The regularization algorithms have additional sophistications to improve convergence. \n",
    "\n",
    "**How do we choose $\\lambda$?**\n",
    "We use cross-validation, just as we discussed before. In fact...Scikit-Learn has versions of Ridge and LASSO regression that do this automatically for you-- see RidgeCV and LassoCV.\n",
    "\n",
    "---\n",
    "\n",
    "### **Locally Linear Regression (LOWESS / LOESS)**\n",
    "\n",
    "LOWESS and LOESS are simple ways to make a smooth curve through data without assuming a fixed formula.\n",
    "\n",
    "How it works:\n",
    "- For each point, it looks at nearby points only.\n",
    "- Gives more importance to points that are closer.\n",
    "- Fits a simple line just to those nearby points.\n",
    "- Does this for every point, making a smooth curve that follows local changes.\n",
    "\n",
    "Why use it?\n",
    "- Very flexible and easy to understand.\n",
    "- Good when the relationship between variables changes in different areas.\n",
    "- Doesn’t force one shape to fit all data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Non-Linear Regression (Overview)**\n",
    "\n",
    "Non-linear regression fits curves or complex shapes to data, not just straight lines.\n",
    "\n",
    "Examples:\n",
    "- S-shaped growth curves\n",
    "- Exponential growth or decay\n",
    "- Neural networks (many layers of curves)\n",
    "\n",
    "How it works:\n",
    "- Uses trial-and-error methods (like gradient descent) to find the best curve.\n",
    "- It can be tricky to find the best fit and might need good starting guesses.\n",
    "- Useful when data clearly isn’t a straight line.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Gaussian Process Regression (GPR)**\n",
    "\n",
    "Gaussian Process Regression is a powerful **non-parametric** regression method. Unlike traditional regression techniques that assume a specific functional form (like a straight line or a polynomial), GPR assumes that the data come from a **distribution over functions**.\n",
    "\n",
    "**What is a Gaussian Process?**\n",
    "\n",
    "A **Gaussian Process (GP)** is a collection of random variables, any finite number of which have a **joint Gaussian distribution**.\n",
    "\n",
    "Think of a GP not as a single curve, but as a *distribution* over all possible smooth curves that could fit your data. When you observe some data points, you can narrow down this distribution and make predictions with uncertainty included.\n",
    "\n",
    "**GPR in Simple Words**\n",
    "\n",
    "- You give GPR some data: $x_i$, $y_i$ (inputs and outputs).\n",
    "- GPR looks at these data and says: \"what are all the *smooth* functions that could have produced this?\"\n",
    "- Then, for a new input $x^*$, it doesn't just give a single $y^*$ value but a **probability distribution** for what $y^*$ could be.\n",
    "\n",
    "**Mathematical Form**\n",
    "\n",
    "Let’s say we want to predict values of $y$ from inputs $x$. In GPR, we assume:\n",
    "\n",
    "$$\n",
    "y(x) \\sim \\mathcal{GP}(m(x), k(x, x'))\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $m(x)$ is the **mean function** (usually taken as zero: $m(x) = 0$).\n",
    "- $k(x, x')$ is the **kernel** or **covariance function**, defining how correlated the outputs are depending on their inputs.\n",
    "\n",
    "A popular choice for the kernel is the **Radial Basis Function (RBF)**:\n",
    "\n",
    "$$\n",
    "k(x, x') = \\sigma_f^2 \\exp\\left( -\\frac{(x - x')^2}{2 \\ell^2} \\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\sigma_f^2$ controls the variance (how \"high\" the function goes),\n",
    "- $\\ell$ is the length scale (how \"wiggly\" the function is).\n",
    "\n",
    "**What GPR Gives You**\n",
    "\n",
    "When you input some new $x^*$ values, GPR gives you:\n",
    "- The **mean** prediction $\\mu(x^*)$\n",
    "- The **variance** $\\sigma^2(x^*)$\n",
    "\n",
    "This means you get **error bars** on every prediction!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1456ea0",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 19** - Classification I </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b6ceab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "936a68d1",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 20** - Classification II </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22e5151",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21bb09e8",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 21** - Deep Learning I </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ad4f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c25d4d5e",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\"> **LECTURE 22** - Deep Learning II </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b64a7a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
