{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "816324f2",
   "metadata": {},
   "source": [
    "### **<span style=\"color:red\"> LECTURE 2  </span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35648beb",
   "metadata": {},
   "source": [
    "### **Probability Density Function (PDF), Cumulative Distribution Function (CDF), and Quantile**\n",
    "\n",
    "- **PDF (Probability Density Function)**: Describes the probability for a continuous variable to take a specific value. The area under the PDF over an interval gives the probability of the variable falling within that interval.\n",
    "- **CDF (Cumulative Distribution Function)**: It is obtained by integrating the PDF from - infinity up to a certain values X. Gives the probability that a random variable is less than or equal to a certain value. \n",
    "- **Quantile**: it's the inverse of the CDF. The value below which a certain percentage of observations fall. For example, the 0.25 quantile (or 25th percentile) is the value below which 25% of the data lie.\n",
    "\n",
    "---\n",
    "\n",
    "### **Empirical and Theoretical Distributions**\n",
    "\n",
    "- **Theoretical Distribution**: A probability distribution derived from a known mathematical model (e.g., Normal, Poisson).\n",
    "- **Empirical Distribution**: Based on observed data. It approximates the distribution of a dataset and is typically represented by the empirical CDF or histogram.\n",
    "- Empirical distributions are used when the true distribution is unknown or difficult to model.\n",
    "\n",
    "---\n",
    "\n",
    "### **Homoscedastic and Heteroscedastic Errors**\n",
    "\n",
    "- **Homoscedasticity**: The variance of the errors is constant.\n",
    "- **Heteroscedasticity**: The error variance changes with the data\n",
    "\n",
    "---\n",
    "\n",
    "### **Kolmogorov's Axioms and Probability**\n",
    "\n",
    "Kolmogorov formalized the foundation of probability with three axioms:\n",
    "\n",
    "1. **Non-negativity**: For any event A, the probability is non-negative:  \n",
    "   \\( P(A) >= 0 \\)\n",
    "2. **Normalization**: The probability of the entire sample space is 1:  \n",
    "   \\( P($\\Omega$) = 1 \\)\n",
    "3. **Additivity**: For any two mutually exclusive events A and B:  \n",
    "   \\( P(A $\\cup$ B) = P(A) + P(B) \\)\n",
    "\n",
    "These axioms form the basis of modern probability theory.\n",
    "\n",
    "---\n",
    "\n",
    "### **Bayes' Theorem**\n",
    "\n",
    "Bayes' Theorem updates the probability of a hypothesis based on new evidence:\n",
    "\n",
    "$\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "$\n",
    "\n",
    "-  P(A|B) : Posterior probability (updated belief)  \n",
    "-  P(B|A) : Likelihood of observing B given A  \n",
    "-  P(A) : Prior probability of A  \n",
    "-  P(B) : Marginal probability of B  \n",
    "\n",
    "Used in many fields like medicine, machine learning, and decision theory.\n",
    "\n",
    "---\n",
    "\n",
    "### **Transformations of Random Variables**\n",
    "\n",
    "Transforming a random variable means applying a function to it, creating a new variable.\n",
    "\n",
    "- **Example**: Let \\( X \\) be a random variable and \\( Y = g(X) \\) a transformation.\n",
    "- To find the **distribution of \\( Y \\)**:\n",
    "  - If \\( X \\) is continuous with PDF \\( $f_X$ \\) and \\( g \\) is invertible, then:\n",
    "\n",
    "$\n",
    "f_Y(y) = f_X(g^{-1}(y)) \\cdot \\left| \\frac{d}{dy} g^{-1}(y) \\right|\n",
    "$\n",
    "\n",
    "- This is used to derive distributions of functions of random variables (e.g., squares, sums, logarithms).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa401bbc",
   "metadata": {},
   "source": [
    "### **<span style=\"color:red\"> LECTURE 3  </span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dd6cd1",
   "metadata": {},
   "source": [
    "### **Monte Carlo Integration (Crude and Hit-or-Miss)**\n",
    "\n",
    "- **Monte Carlo integration** uses random sampling to approximate definite integrals.\n",
    "- **Crude Monte Carlo**:  \n",
    "  Estimate the integral $\\int_a^b f(x) \\, dx$ by sampling $x_i \\sim \\mathcal{U}(a, b)$ and computing:  \n",
    "  $$\n",
    "  I \\approx (b - a) \\cdot \\frac{1}{N} \\sum_{i=1}^N f(x_i)\n",
    "  $$\n",
    "- **Hit-or-Miss method**:  \n",
    "  Sample uniformly in a rectangle that encloses the graph of $f(x)$.  \n",
    "  The integral is approximated by the fraction of points that fall below the curve times the area of the rectangle.\n",
    "\n",
    "---\n",
    "\n",
    "### **Mean, Median, and Expected Value**\n",
    "\n",
    "- **Mean**: Arithmetic average of a dataset.\n",
    "- **Median**: Middle value when data are ordered. Less sensitive to outliers.\n",
    "- **Expected value** ($\\mathbb{E}[X]$): Theoretical mean of a random variable. For continuous variables:  \n",
    "  $$\n",
    "  \\mathbb{E}[X] = \\int x f(x) \\, dx\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "### **Standard Deviation, MAD (1), Variance, MAD (2), Quantile Region, Interquantile Range, Mode**\n",
    "\n",
    "- **Standard deviation** ($\\sigma$): Measures spread around the mean.\n",
    "- **MAD_1 (Mean Absolute Deviation)**:  \n",
    "  $$\n",
    "  \\text{MAD}_1 = \\frac{1}{N} \\sum_{i=1}^N |x_i - \\bar{x}|\n",
    "  $$\n",
    "- **Variance**:  \n",
    "  $$\n",
    "  \\text{Var}(X) = \\mathbb{E}[(X - \\mu)^2]       with \\mu = \\mathbb{E}[X])\n",
    "  $$\n",
    "- **MAD_2**: Median Absolute Deviation = median $(|x_i - median({x_i})|)$\n",
    "- **Quantile region**: Range containing a central portion of the distribution (e.g., 95% interval).\n",
    "- **Interquantile range (IQR)**:  \n",
    "  $$\n",
    "  \\text{IQR} = Q_{75} - Q_{25}\n",
    "  $$\n",
    "\n",
    "It contain the 50% of the dataset\n",
    "- **Mode**: Most frequent value in a dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### **Skewness and Kurtosis**\n",
    "\n",
    "- **Skewness**: Measures asymmetry of a distribution.\n",
    "  - Positive skew: tail to the right.\n",
    "  - Negative skew: tail to the left.\n",
    "- **Kurtosis**: Measures how likely extreme values (far from the average) are in a distribution.\n",
    "  - High kurtosis: heavy tails.\n",
    "  - Low kurtosis: light tails.\n",
    "  - Normal distribution has kurtosis $= 3$.\n",
    "\n",
    "---\n",
    "\n",
    "### **PDF vs Sample Statistics, Bessel's Correction**\n",
    "\n",
    "- **PDF statistics**: Theoretical values (mean, variance, etc.) computed from a probability distribution.\n",
    "- **Sample statistics**: Estimates of these quantities based on data.\n",
    "- **Bessel’s correction**: When estimating variance from a sample, divide by $N - 1$ instead of $N$ to correct bias:  \n",
    "  $$\n",
    "  s^2 = \\frac{1}{N - 1} \\sum_{i=1}^N (x_i - \\bar{x})^2\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "### **Uncertainties of Estimators**\n",
    "\n",
    "- Every estimator has **uncertainty** due to finite sample size.\n",
    "- For the **sample mean**:\n",
    "  $$\n",
    "  \\text{Standard error} = \\frac{\\sigma}{\\sqrt{N}}\n",
    "  $$\n",
    "- For the **sample variance** and **standard deviation** ($s$), the standard error can be approximated as:\n",
    "  $$\n",
    "  \\text{SE}(s) \\approx \\frac{\\sigma}{\\sqrt{2N}}\n",
    "  $$\n",
    "  where $\\sigma$ is the true standard deviation and $N$ is the sample size.\n",
    "- For the **Interquantile Range (IQR)**, the uncertainty depends on the density around the quartiles; a rough estimate of its standard error is:\n",
    "  $$\n",
    "  \\text{SE}(\\text{IQR}) \\approx \\frac{1.58 \\times \\text{IQR}}{\\sqrt{N}}\n",
    "  $$\n",
    "- Confidence intervals express the likely range of the true parameter.\n",
    "\n",
    "---\n",
    "\n",
    "### **PDFs: Uniform, Gaussian, Log-Normal, Chi-Squared, Poisson**\n",
    "\n",
    "- **Uniform**: All values in an interval have equal probability.  \n",
    "  $$\n",
    "  f(x) = \\frac{1}{b - a}      \\text{    for   } x \\in [a, b]\n",
    "  $$\n",
    "\n",
    "  this distribution has $\\sigma = \\frac{b-a}{\\sqrt(12)}$\n",
    "- **Gaussian (Normal)**: Curve defined by mean $\\mu$ and std $\\sigma$.  \n",
    "  $$\n",
    "  f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\, e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\n",
    "  $$\n",
    "  - The convolution of two gaussian is a gaussian too.\n",
    "  - It's the quuen of distribution , because everything follow this shape and it's quite easy to use.\n",
    "  - $1\\sigma$ = 68% // $2\\sigma$ = 95%\n",
    "\n",
    "- **Log-Normal**: $X \\sim \\text{LogNormal}$ means $\\ln X \\sim \\text{Normal}$.\n",
    "- **Chi-squared** ($\\chi^2$):  \n",
    "  If we define standardized variables as  \n",
    "  $$\n",
    "  z_i = \\frac{x_i - \\mu}{\\sigma},\n",
    "  $$  \n",
    "  then the sum of their squares  \n",
    "  $$\n",
    "  Q = \\sum_{i=1}^K z_i^2\n",
    "  $$  \n",
    "  follows a **chi-squared distribution** with $K$ degrees of freedom.\n",
    "\n",
    "  The number of degrees of freedom $K$ is equal to the number of **independent** data points used in the sum.\n",
    "\n",
    "- **Poisson**: Discrete distribution for count data.  \n",
    "  $$\n",
    "  P(k; \\mu) = \\frac{\\mu^k e^{-\\mu}}{k!}\n",
    "  $$\n",
    "  - Where: $\\mu$ is the mean, K is the number of events occouring\n",
    "  - Known as \"law of rare events\"\n",
    "\n",
    "---\n",
    "\n",
    "### **Importance Sampling**\n",
    "\n",
    "- Hit or miss and Crude MC, are inefficient if the integrand has some null zone, or even if is really extendended... that's beacuse this 2 methode use the uniform distribution.\n",
    "- Instead of sampling from the uniform, sample from a **proposal distribution** $g(x)$ \n",
    "- Best when $g(x)$ is close to the shape of $f(x)$.\n",
    "- Reduces variance and computational cost if the $g(x)$ it's well chosen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea58c2c4",
   "metadata": {},
   "source": [
    "### **<span style=\"color:red\"> LECTURE 4  </span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc59594",
   "metadata": {},
   "source": [
    "### **Central Limit Theorem (CLT)**\n",
    "\n",
    "- The CLT states that the sum (or mean) of a large number of independent, identically distributed random variables tends to follow a **normal distribution**, regardless of the original distribution.\n",
    "\n",
    "---\n",
    "\n",
    "### **Law of Large Numbers (LLN)**\n",
    "\n",
    "- The LLN states that as the number of observations $N$ increases, the sample mean $\\bar{x}$ converges to the true mean $\\mu$:\n",
    "  $$\n",
    "  \\lim_{N \\to \\infty} \\bar{x} = \\mu\n",
    "  $$\n",
    "- This is a statement about convergence **in probability**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Multidimensional PDFs**\n",
    "\n",
    "- In 2D, the joint distribution can be described by:\n",
    "  - **Mean vector**:  \n",
    "    $$\n",
    "    \\vec{\\mu} = (\\mu_x, \\mu_y)\n",
    "    $$\n",
    "\n",
    "  - **Covariance matrix**:  \n",
    "    $$\n",
    "    \\Sigma = \\begin{pmatrix}\n",
    "    \\sigma_x^2 & \\text{cov}(x, y) \\\\\n",
    "    \\text{cov}(y, x) & \\sigma_y^2\n",
    "    \\end{pmatrix}\n",
    "    $$\n",
    "    The two off diagonal values are equal to 0 only if x & y are totaly uncorrelated\n",
    "\n",
    "  - **Correlation coefficient**:  \n",
    "    $$\n",
    "    \\rho = \\frac{\\text{cov}(x, y)}{\\sigma_x \\sigma_y}\n",
    "    $$\n",
    "    Express the percentual of correlation between the 2 variable\n",
    "\n",
    "  - **Principal axes**: determined by the eigenvectors of $\\Sigma$; note that the correlation vanish in this system by definition.\n",
    "  - **2D Confidence Ellipses**: regions where the joint probability is constant, keep attention, for each dimension the number of sigma has a different meaning: $1\\sigma = 39$% in 2 dimension! I can impose 68% for the similitude with 1D, but it's not $1\\sigma$.\n",
    "\n",
    "---\n",
    "\n",
    "### **Correlation vs Causation**\n",
    "\n",
    "Correlation does not imply causation!\n",
    "Just because the sun burns our skin and also makes us thirsty, it doesn't mean that thirst causes sunburn!\n",
    "\n",
    "- **Pearson's correlation** (r) : Measures linear correlation between 2 different dataset; it's a value between -1 and 1, the 2 are uncorrelated only if r = 0.\n",
    "It has 2 problems:\n",
    "  - it's susceptible at the outliars\n",
    "  - doesn't count the error\n",
    "\n",
    "- **Spearman's rho**: Measures monotonic (rank-based) correlation.\n",
    "- **Kendall's tau**: Measures ordinal association between two variables.\n",
    "\n",
    "---\n",
    "\n",
    "### **Rejection Sampling**\n",
    "\n",
    "Rejection sampling is a method to generate random samples from a complex distribution $p(x)$, using a simpler proposal distribution $q(x)$.\n",
    "\n",
    "The procedure works as follows:\n",
    "\n",
    "1. **Choose a proposal distribution** $q(x)$ from which it's easy to sample (often a uniform distribution).  \n",
    "   Make sure it's \"wide enough\" to cover the shape of $p(x)$, including its tails.\n",
    "\n",
    "2. **Find a constant** $M$ such that for all $x$:\n",
    "   $$\n",
    "   p(x) \\leq M q(x)\n",
    "   $$\n",
    "   This ensures the proposal dominates the target distribution.\n",
    "\n",
    "3. **Generate a candidate sample** $x $ from $q(x)$.\n",
    "\n",
    "4. **Draw a random number** $u $ from $ \\mathcal{U}(0, 1)$.\n",
    "\n",
    "5. **Accept or reject**:\n",
    "   - Accept $x$ if  \n",
    "     $$\n",
    "     u < \\frac{p(x)}{M q(x)}\n",
    "     $$\n",
    "   - Otherwise, reject $x$ and go back to step 3.\n",
    "\n",
    "The set of accepted $x$ values will follow the target distribution $p(x)$.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Inverse Transform Sampling**\n",
    "\n",
    "- Used to sample from a distribution with known CDF $F(x)$ and Quantile.\n",
    "- Steps:\n",
    "  1. Sample $u$ from  ${U}(0, 1)$.\n",
    "  2. Compute $x = F^{-1}(u)$.\n",
    "Normalizarion here are rellly important.\n",
    "you can retrive the quantile and the CDF by numerically solution if you are not able to do in by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012b4cd6",
   "metadata": {},
   "source": [
    "### **<span style=\"color:red\"> LECTURE 5  </span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b71a25",
   "metadata": {},
   "source": [
    "### **Population, Sample, Statistic, Estimators, Uncertainty and Intervals**\n",
    "\n",
    "- A **population** is the full set of data or measurements we are interested in.\n",
    "- A **sample** is a subset of the population, used to infer properties of the whole.\n",
    "- A **statistic** is a function of the sample (e.g. the sample mean $\\bar{x}$).\n",
    "- An **estimator** is a rule or formula to estimate population parameters from the sample.\n",
    "- All estimators have **uncertainties** due to random sampling.\n",
    "- A **confidence interval**, gives a range likely to contain the true value.\n",
    "\n",
    "---\n",
    "\n",
    "### **Frequentist vs Bayesian**\n",
    "\n",
    "- **Frequentist**: Probability is extract from the frequency of events. Parameters are fixed, data are random.\n",
    "Into Frequentist inference we have confidence levels,.\n",
    "- **Bayesian**: Probability expresses belief or uncertainty about what we know. Parameters have distributions while data are fixed. In Bayesian inference we have credible regions derive from posterior distribution of the parameters.\n",
    "\n",
    "\n",
    "- Bayesian statistic it's hold by the **Bayes’ theorem**:\n",
    "  $$\n",
    "  P(\\theta | \\text{data}) = \\frac{P(\\text{data} | \\theta) \\cdot P(\\theta)}{P(\\text{data})}\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "### **Maximum Likelihood Estimator (MLE)**\n",
    "\n",
    "- The **MLE** is the value of the parameter $\\theta$ that **maximizes the likelihood** of the observed data:\n",
    "  $$\n",
    "  \\hat{\\theta}_{\\text{MLE}} = \\arg \\max_\\theta \\mathcal{L}(\\theta)\n",
    "  $$\n",
    "- It's usefull in both frequentist e bayesian approach\n",
    "- **Remember**: the **likelihood** is defined as the product of the probabilities (or probability densities) of the observed data, assuming a given model or parameter value.\n",
    "\n",
    "  For independent data points $x_1, x_2, ..., x_N$:\n",
    "\n",
    "  $$\n",
    "  \\mathcal{L}(\\theta) = \\prod_{i=1}^{N} p(x_i \\mid \\theta)\n",
    "  $$\n",
    "\n",
    "  Where:\n",
    "  - $\\mathcal{L}(\\theta)$ is the likelihood function,\n",
    "  - $p(x_i \\mid \\theta)$ is the probability (or density) of observing $x_i$ given parameter $\\theta$,\n",
    "  - The product assumes all $x_i$ are independent.\n",
    "\n",
    "  Often, we work with the **log-likelihood**:\n",
    "  $$\n",
    "  \\log \\mathcal{L}(\\theta) = \\sum_{i=1}^{N} \\log p(x_i \\mid \\theta)\n",
    "  $$\n",
    "  which is easier to compute and optimize.\n",
    "\n",
    "---\n",
    "\n",
    "### **Properties of Estimators**\n",
    "\n",
    "- **Unbiasedness**: $\\mathbb{E}[\\hat{\\theta}] = \\theta$\n",
    "- **Consistency**: $\\hat{\\theta} \\to \\theta$ as $N \\to \\infty$\n",
    "- **Efficiency**: Minimum possible variance (called Cramer-Rao bound)\n",
    "\n",
    "---\n",
    "\n",
    "### **Likelihood, Chi-squared and Minimization**\n",
    "\n",
    "- The **likelihood** $\\mathcal{L}(\\theta)$ is the probability of the data given parameters.\n",
    "- If we infere that the process has a gaussian distribution the Likelihood will follow the $\\exp(-\\chi^2/2)$\n",
    "- In Gaussian cases, maximizing the log-likelihood is equivalent to **minimizing the chi-squared**:\n",
    "  $$\n",
    "  \\chi^2 = \\sum_{i=1}^N \\left( \\frac{x_i - f(x_i; \\theta)}{\\sigma_i} \\right)^2\n",
    "  $$\n",
    "- Minimizing $\\chi^2$ gives the best-fit parameters.\n",
    "- The MLE method tell us to think the likelihood as a function of the (unknown) model parameters, and by minimizing the $\\chi^2$, we will find the values that maximize the values of the likelihood.\n",
    "\n",
    "---\n",
    "\n",
    "### **Mean and MLE Error: Homoscedastic vs Heteroscedastic**\n",
    "\n",
    "- **Homoscedastic**: All data points have the same uncertainty $\\sigma$. We Will use the mean:\n",
    "    $$\n",
    "    \\bar{x} = \\frac{1}{N} \\sum x_i \\quad \\text{and} \\quad \\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{N}}\n",
    "    $$\n",
    "- **Heteroscedastic**: Uncertainties vary for each data point $\\sigma_i$. Then use a **weighted mean**:\n",
    "    $$\n",
    "    \\bar{x} = \\frac{\\sum x_i / \\sigma_i^2}{\\sum 1 / \\sigma_i^2}\n",
    "    $$\n",
    "    $$\n",
    "    \\sigma_{\\bar{x}}^2 = \\frac{1}{\\sum 1/\\sigma_i^2}\n",
    "    $$\n",
    "This two formula are extracted from the derivative of the log-Likelihood = 0 , that' because we are searching for a maximum.\n",
    "\n",
    "Our Maximum Likelihood Estimator (MLE) is not perfect — every estimate has an associated **uncertainty** due to the finite sample size.\n",
    "\n",
    "Under general conditions, the MLE becomes **asymptotically normal**, meaning that for large $N$, the likelihood function can be approximated by a **Gaussian** centered at the true parameter value $\\theta_0$.\n",
    "\n",
    "To quantify the uncertainty, we expand the **log-likelihood** around its maximum using a second-order **Taylor expansion**:\n",
    "\n",
    "$$\n",
    "\\log \\mathcal{L}(\\theta) \\approx \\log \\mathcal{L}(\\hat{\\theta}) - \\frac{1}{2} (\\theta - \\hat{\\theta})^2 F(\\hat{\\theta})\n",
    "$$\n",
    "\n",
    "Here, $F(\\hat{\\theta})$ is the **Fisher Information Matrix**, defined as the negative second derivative (Hessian) of the log-likelihood:\n",
    "\n",
    "$$\n",
    "F(\\theta) = - \\frac{\\partial^2}{\\partial \\theta_i \\partial \\theta_j} \\log \\mathcal{L}(\\theta)\n",
    "$$\n",
    "\n",
    "The **covariance matrix** of the estimator $\\hat{\\theta}$ is then given by the **inverse** of the Fisher matrix:\n",
    "\n",
    "$$\n",
    "\\text{Cov}(\\hat{\\theta}) = F^{-1}(\\hat{\\theta})\n",
    "$$\n",
    "\n",
    "For a **single parameter** $\\theta$, this simplifies to:\n",
    "\n",
    "$$\n",
    "\\sigma_{\\hat{\\theta}} = \\sqrt{\\frac{1}{F(\\hat{\\theta})}}\n",
    "$$\n",
    "\n",
    "This implies that asymptotically, the MLE is **normally distributed**:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} \\sim \\mathcal{N} \\left( \\theta_0, F^{-1}(\\theta_0) \\right)\n",
    "$$\n",
    "---\n",
    "\n",
    "### **Non-Gaussian Likelihoods**\n",
    "\n",
    "- When the data doesn’t follow a Gaussian distribution, use the appropriate **likelihood model**, such as : **Poisson**, **Binomial**, **Exponential**, **Log-normal**, etc.\n",
    "- The MLE approach still applies: choose the model, write the likelihood, and maximize it numerically.\n",
    "- In most of the cases, you will find the same result as in the gaussian one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa14af5",
   "metadata": {},
   "source": [
    "### **<span style=\"color:red\"> LECTURE 6 </span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe2ed34",
   "metadata": {},
   "source": [
    "### **Fit**\n",
    "\n",
    "- Fitting means adjusting model parameters so that the model best matches the observed data.\n",
    "- Typically done by minimizing a loss function, such as the **sum of squared residuals** or **negative log-likelihood**.\n",
    "- The goal is to find the best estimate $\\hat{\\theta}$ that explains the data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Outliers and Huber Loss Function**\n",
    "\n",
    "- **Outliers** are data points that deviate significantly from the trend of the rest of the data.\n",
    "- Standard least squares are very sensitive to outliers.\n",
    "- How do we deal with outliers? By modifying the likelihood!\n",
    "- The **Huber loss** combines the squared loss for small errors and absolute loss for large errors:\n",
    "\n",
    "$$\n",
    "L_{\\text{Huber}}(t) =\n",
    "\\begin{cases}\n",
    "\\frac{1}{2} t^2 & \\text{if } |t| \\leq c \\\\\n",
    "c |t| - \\frac{1}{2} c^2 & \\text{if } |t| > c\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- Where $t = \\left( \\frac{y - M(\\theta)}{\\sigma} \\right)$ represents the **standardized residual**, i.e. how far the observed value $y$ is from the model prediction $M(\\theta)$, in units of the known uncertainty $\\sigma$.\n",
    "- $c$ is the **tuning constant** (or confidence threshold), which determines the cutoff point where the loss switches from quadratic to linear. A common value is $c \\approx 1.345$, which gives good balance between efficiency and robustness under normal errors.\n",
    "- This approach makes the fit more **robust** to outliers: small residuals behave like in least squares, but large residuals are penalized less harshly.\n",
    "- Note that by doing this, we are effectively putting **prior information** into the analysis\n",
    "\n",
    "---\n",
    "\n",
    "### **Goodness of Fit : Reduced Chi-squared**\n",
    "\n",
    "- Measures how well the model describes the data. Remember GIGO (Garbage In Garbage Out), if the model is wrong , finding the \"best\" parameter doesn't really mean something ...\n",
    "- A good fit should show residuals randomly scattered around zero.\n",
    "\n",
    "- The **reduced chi-squared** is defined as:\n",
    "\n",
    "$$\n",
    "\\chi^2_{\\text{red}} = \\frac{1}{\\nu} \\sum_{i=1}^N \\left( \\frac{y_i - f(x_i)}{\\sigma_i} \\right)^2\n",
    "$$\n",
    "\n",
    "where $\\nu = N - k$ is the number of degrees of freedom (data points minus number of parameters).\n",
    "\n",
    "- Interpretation:\n",
    "  - $\\chi^2_{\\text{red}} \\approx 1$: good fit\n",
    "  - $\\chi^2_{\\text{red}} \\gg 1$: underfitting or underestimated errors\n",
    "  - $\\chi^2_{\\text{red}} \\ll 1$: overfitting or overestimated errors\n",
    "- If the model is **wrong** (misspecified), goodness-of-fit measures can be misleading.\n",
    "\n",
    "---\n",
    "\n",
    "### **Model Comparison, Occam’s Razor , AIC and BIC**\n",
    "- You can't do $\\chi^2_{\\text{red}}$ with Huber function, because it's not gaussian!\n",
    "- When comparing two models with the **same number of parameters**, we can simply compare their **maximum log-likelihood** values:\n",
    "- Larger log-likelihood ⇒ better fit\n",
    "\n",
    "The **Huber loss** clearly performs better (less negative log-likelihood), meaning it fits the data more effectively, especially in the presence of outliers.\n",
    "\n",
    "\n",
    "When models have **different numbers of parameters**, simply comparing likelihoods is not fair: more complex models might fit better **just by chance**. We need to penalize complexity — this is known as the **Occam penalty**.\n",
    "\n",
    "\n",
    "A simple method to compare models with different complexity is the **AIC** (Akaike Information Criterion):\n",
    "  \n",
    "- Lower AIC is better for the explaination of the dataset\n",
    "- It's composed by lot of term, the first one it's the $\\chi^2$, the second and third penalize model complexity\n",
    "- If models fit the data equally well, AIC prefers the one with fewer parameters.\n",
    "\n",
    "\n",
    "\n",
    "The **BIC** (Bayesian Information Criterion) is another way to compare models, especially when they have different numbers of parameters.\n",
    "It’s similar to AIC, but it **penalizes complex models more strongly**, especially when the dataset is large.\n",
    "\n",
    "\n",
    "- Lower **BIC** means a better model.\n",
    "- BIC prefers **simpler models**, especially when $n$ is large.\n",
    "- It’s often used in **Bayesian statistics**, but doesn’t need a full Bayesian analysis, often use in frequentist analysis too.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Bootstrap**\n",
    "\n",
    "- A **resampling method** to estimate uncertainties and confidence intervals.\n",
    "- Keep attention : it create information out of nothing!\n",
    "- Steps:\n",
    "  1. Resample data (with replacement) to create many datasets. The probability of getting the original dataset it's extreamly low ($N! / N^N$)\n",
    "  2. Fit the model to each resampled dataset.\n",
    "  3. Analyze the distribution of the fitted parameters.\n",
    "- Useful when analytical uncertainty is hard to compute or it's too big (such as when we have few point for a gaussian distribution).\n",
    "\n",
    "---\n",
    "\n",
    "###  **Jackknife Method** \n",
    "\n",
    "The **Jackknife** is a method to estimate the **uncertainty** (standard error) and **bias** of a statistic — like the **mean** or **standard deviation** — using your data.\n",
    "\n",
    "Suppose you have a dataset of $N$ values.\n",
    "\n",
    "1. Leave out **one** data point at a time → you get $N$ new datasets.\n",
    "2. Compute your statistic (e.g. mean, std) on each of these.\n",
    "3. From the $N$ results, estimate:\n",
    "   - A **better (bias-corrected)** value of the statistic\n",
    "   - The **uncertainty** on that value\n",
    "\n",
    "\n",
    "Jackknife works **well** when the statistic is:\n",
    "- The **mean**\n",
    "- The **standard deviation**\n",
    "\n",
    "It works **poorly** for:\n",
    "- The **median**\n",
    "- **Quantiles** (e.g. the 25th percentile)\n",
    "\n",
    "These are called **rank-based statistics**, and removing one point at a time doesn’t change them much — so the jackknife underestimates the uncertainty.\n",
    "\n",
    "---\n",
    "\n",
    "##  Jackknife vs Bootstrap\n",
    "\n",
    "|                | Jackknife                | Bootstrap                |\n",
    "|----------------|--------------------------|--------------------------|\n",
    "| Type           | Leaves out one point     | Resamples with replacement |\n",
    "| Fast?          | ✅ Yes                   | ❌ Slower               |\n",
    "| Repeatable?    | ✅ Always same result     | ❌ Changes each time    |\n",
    "| Works for all stats? | ❌ Not for medians       | ✅ Yes                 |\n",
    "| Confidence intervals | ❌ Approximate         | ✅ Full distribution     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a611a0",
   "metadata": {},
   "source": [
    "### **<span style=\"color:red\"> LECTURE 7  </span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8008fa4",
   "metadata": {},
   "source": [
    "### **<span style=\"color:red\"> LECTURE 8  </span>**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
